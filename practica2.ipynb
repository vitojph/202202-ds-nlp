{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KSchool - Master Online Data Science \n",
    "\n",
    "## Técnicas Avanzadas de Inteligencia Artificial\n",
    "\n",
    "### Módulo 4: Procesamiento del Lenguaje Natural - Actividad de evaluación 2\n",
    "\n",
    "\n",
    "# Estructura de la actividad\n",
    "\n",
    "- [Descripción de la actividad](#descripcion)\n",
    "- [Conjunto de datos](#datos)\n",
    "- [Criterios de evaluación](#evaluacion)\n",
    "- [Formato y fecha de entrega](#entrega)\n",
    "- [Ejercicio 1: Algoritmo de ML Tradicional para Clasificación de Texto](#ejercicio1)\n",
    "- [Ejercicio 2: Modelos de Lenguaje Pre-entrenados para Representar el Contenido Semántico del Texto](#ejercicio2)\n",
    "- [Ejercicio 3: Algoritmo de DL para Clasificación de Texto](#ejercicio3)\n",
    "- [Ejercicios opcionales¶](#opcionales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"descripcion\"></a>\n",
    "# Descripción de la actividad\n",
    "\n",
    "En este segundo ejercicio práctico del módulo tendrás que entrenar y evaluar diferentes tipos de clasificadores de texto utilizando distintos mecanismos para representar los textos de entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"datos\"></a>\n",
    "# Conjuntos de datos\n",
    "\n",
    "Para entrenar los distintos clasificadores de texto vamos a utilizar dos colecciones de datos públicas bastante conocidas en el mundillo:\n",
    "\n",
    "- las [críticas de películas de IMDb](https://ai.stanford.edu/~amaas/data/sentiment/), un dataset muy habitual en tareas de análisis de opinión que vamos a utilizar para clasificación de texto binaria\n",
    "- las [noticias de AG News](https://www.kaggle.com/amananandrai/ag-news-classification-dataset/), una colección de noticias organizadas en cuatro categorías muy habitual en tareas de clasificación de texto multiclase.\n",
    "\n",
    "Ambos datasets están disponibles en multitud de sitios, pero te invito a acceder a ellos utilizando [la librería `datasets` de HuggingFace](https://github.com/huggingface/datasets). \n",
    "\n",
    "Para ello, asegúrate de ejecurtar la siguiente celda para instalar la librería y otra dependencia que necesitaremos más adelante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, cargamos las dos colecciones de datos en dos objetos Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "imdb = load_dataset(\"imdb\")\n",
    "ag_news = load_dataset(\"ag_news\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos objetos tienen forma de tabla, con filas y columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imdb)\n",
    "\n",
    "print(f\"dimensiones: {imdb.shape}\")\n",
    "print(f\"filas: {imdb.num_rows}\")\n",
    "print(f\"columnas: {imdb.num_columns}\")\n",
    "print(f\"\"\"muestras en el set de entrenamiento: {len(imdb[\"train\"])}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb[\"train\"][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas estructuras de datos son compatibles con otras herramientas habituales en Ciencia de Datos como `pandas`, `numpy` o `pytorch`. Tómate tu tiempo para explorar el contenido y revisa [la documentación para aprender a operar y transformar estos objetos](https://huggingface.co/docs/datasets/master/exploring.html) en otras estructuras de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb.set_format(type=\"pandas\", columns=[\"text\", \"label\"])\n",
    "imdb[\"train\"][-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"evaluacion\"></a>\n",
    "# Criterios de evaluación\n",
    "\n",
    "Para la evaluación del ejercicio no es suficiente con proporcionar código y que este funcione. Es imprescindible proporcionar respuestas claras, justificar las decisiones tomadas, explicando pros y contras, y demostrar que se entiende en cada momento lo que se está haciendo.\n",
    "\n",
    "Para ello, no dudes en añadir todo el texto que necesites, ya sea como comentarios de código o en celdas Markdown aparte.\n",
    "\n",
    "\n",
    "| Apartado \t| Criterio de evaluación \t| Peso \t|\n",
    "|:-:\t|:-:\t|:-:\t|\n",
    "| Ejercicio 1 \t| la solución es completa y correcta \t| 10% \t|\n",
    "| Ejercicio 2 \t| la solución es completa y correcta \t| 25% \t|\n",
    "| Ejercicio 3 \t| la solución es completa y correcta \t| 40% \t|\n",
    "| Ejercicios opcionales \t|  originalidad y claridad\t| 10% \t|\n",
    "| Entrega general \t| limpieza y claridad de código y respuestas \t| 15% \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"entrega\"></a>\n",
    "# Formato y fecha de entrega\n",
    "\n",
    "El cuaderno resuelto, una vez completado y listo para su entrega, deberá exportarse a formato HTML con el siguiente nombre de fichero: `apellidos-nombre-a11-mod4-2.html`\n",
    "\n",
    "**Fecha de entrega**: TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ejercicio1\"></a>\n",
    "# Ejercicio 1: Algoritmo de ML Tradicional para Clasificación de Texto\n",
    "\n",
    "En este primer ejercicio vamos a entrenar y evaluar un par de clasificadores de texto utilizando una estrategia basada en aprendizaje automático _tradicional_: \n",
    "\n",
    "1. entrenaremos un clasificador basado en _Support Vector Machine_\n",
    "2. representaremos los textos de entrada como los pesos tf.idf del vocabulario\n",
    "3. tokenizaremos las palabras e ignoraremos las _stop words_, es decir, palabras como preposiciones, determinantes y conjunciones que normalmente no proporcionan contenido semántico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "# cargamos una lista de stop words o palabras sin contenido léxico, que querremos ignorar\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# definimos una pipeline que combina el vectorizador y el clasificador SVM\n",
    "model_sentiment = Pipeline([\n",
    "                (\"tfidf\", TfidfVectorizer(stop_words=stop_words)),\n",
    "                (\"clf\", LinearSVC()),\n",
    "            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos y evaluamos un primer clasificador de texto con el dataset de IMDb para identificar opiniones positivas y negativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenamos el modelo con el dataset de IMDb\n",
    "model_sentiment.fit(imdb[\"train\"][\"text\"], imdb[\"train\"][\"label\"])\n",
    "    \n",
    "# una vez entrenado, generamos las predicciones con el test set\n",
    "y_pred = model_sentiment.predict(imdb[\"test\"][\"text\"])\n",
    "\n",
    "# y calculamos las métricas de evaluación\n",
    "metrics = precision_recall_fscore_support(imdb[\"test\"][\"label\"], y_pred, average=\"macro\")\n",
    "print(f\"Precisión: {metrics[0]}\")\n",
    "print(f\"Cobertura: {metrics[1]}\")\n",
    "print(f\"medida f: {metrics[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos qué tal funciona con algunas frases de ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ejemplos = [\n",
    "    \"I really enjoyed the movie :-) It was superb!\",\n",
    "    \"The actors and the filmaker are so bad I had to leave the movie theater before the end\",\n",
    "    \"I love ice-cream\"\n",
    "]\n",
    "\n",
    "polaridad = [\"Negativa\", \"Positiva\"]\n",
    "\n",
    "for ejemplo in ejemplos:\n",
    "  prediccion = model_sentiment.predict([ejemplo])[0]\n",
    "  print(f\"{ejemplo} -> {polaridad[prediccion]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora vamos a repetir la operacion entrenando otro clasificador con el dataset de AG News para categorizar automáticamente noticias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos una pipeline que combina el vectorizador y el clasificador SVM\n",
    "model_news = Pipeline([\n",
    "                (\"tfidf\", TfidfVectorizer(stop_words=stop_words)),\n",
    "                (\"clf\", LinearSVC()),\n",
    "            ])\n",
    "\n",
    "# entrenamos el modelo con el dataset de AG News\n",
    "model_news.fit(ag_news[\"train\"][\"text\"], ag_news[\"train\"][\"label\"])\n",
    "    \n",
    "# una vez entrenado, generamos las predicciones con el test set\n",
    "y_pred = model_news.predict(ag_news[\"test\"][\"text\"])\n",
    "\n",
    "# y calculamos las métricas de evaluación\n",
    "metrics = precision_recall_fscore_support(ag_news[\"test\"][\"label\"], y_pred, average=\"macro\")\n",
    "print(f\"Precisión: {metrics[0]}\")\n",
    "print(f\"Cobertura: {metrics[1]}\")\n",
    "print(f\"medida f: {metrics[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y probemos las predicciones del modelo con supuestos titulares de noticias inventados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ejemplos = [\n",
    "            \"Spain will face the United States in the next basketball World Championships.\",\n",
    "            \"United Kingdom to leave the European Union by 2021, officials said.\",\n",
    "            \"IBM to present the latest technology next Monday\",\n",
    "            \"Inflaction and job cuts worry the stock market\",\n",
    "            ]\n",
    "\n",
    "categorias = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
    "for ejemplo in ejemplos:\n",
    "  prediccion = model_news.predict([ejemplo])[0]\n",
    "  print(f\"{ejemplo} -> {categorias[prediccion]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ejercicio2\"></a>\n",
    "# Ejercicio 2: Modelos de Lenguaje Pre-entrenados para Representar el Contenido Semántico del Texto\n",
    "\n",
    "En este segundo ejercicio tendrás que mejorar los modelos anteriores. Para ello, entrena y evalúa un par de clasificadores de texto nuevos manteniendo el algoritmo _tradicional_ de ML pero sustituyendo el proceso de extracción de características y vectorización basado en tf.idf por alguno de los modelos de lenguaje contextual que hemos visto durante el módulo.\n",
    "\n",
    "La idea que subyace es que cualquier modelo de lenguaje debería capturar de manera más eficaz el contenido linguístico del texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escribe tu código aquí\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ejercicio3\"></a>\n",
    "# Ejercicio 3: Algoritmo de DL para Clasificación de Texto\n",
    "\n",
    "En el tercer ejercicio tendrás que entrenar y evaluar un par de clasificadores de texto utilizando alguna de las arquitecturas de _Deep Learning_ que has aprendido durante la asignatura.\n",
    "\n",
    "Lo que queremos comprobar ahora es si una arquitectura más sofisticada como puede ser una red neuronal profunda es capaz de mejorar el rendimiento de un clasificador de basado en _Support Vector Machines_, aunque sea a costa de añadir complejidad al proceso de entrenamiento. ¿Puedes mejorar los resultados al entrenar por ejemplo un perceptrón multicapa? ¿Puedes continuar la mejora añadiendo capas y neuronas?\n",
    "\n",
    "A partir de este ejercicio, si vas a entrenar una red profunda, es aconsejable que entrenes los clasificadores en un entorno optimizado con aceleración por hardware. Para ello, abre el cuaderno en [Google Colab](https://colab.research.google.com/) y asegúrate de arrancar una instancia con tarjeta gráfica. Simplemente haz clic en las opciones *Entorno de ejecución* > *Cambiar tipo de entorno de ejecución* > *Acelerador por hardware GPU*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escribe tu código aquí\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"opcionales\"></a>\n",
    "# Ejercicios opcionales\n",
    "\n",
    "Este ejercicio es completamente abierto y puedes tratar de construir nuevos clasificadores con el objetivo de mejorar los evaluaciones obtenidas en los ejercicios anteriores.\n",
    "\n",
    "¿Puedes mejorar los resultados al entrenar por una red neuronal de tipo CNN, LSTM o basada en Transformer? Si tienes curiosidad por saber cuáles son las soluciones que mejor resultado dan, consulta cuáles son los mejores sistemas en [la página dedicada a la clasificación de texto en _Papers with Code_](https://www.paperswithcode.com/task/text-classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escribe tu código aquí\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
