{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@import url('https://fonts.googleapis.com/css?family=Montserrat');\n",
       "\n",
       "h1, h2, h3 {\n",
       "    font-family: Montserrat;\n",
       "    font-weight: bold;\n",
       "    position: static;\n",
       "    color: #ffcf21;\n",
       "}\n",
       "\n",
       "p, li {\n",
       "    font-family: Montserrat;\n",
       "    size: 11px;\n",
       "    text-align: justify;\n",
       "    text-justify: inter-word;\n",
       "}\n",
       "\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# esta celda controla el estilo del cuaderno\n",
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerías de PLN en Python\n",
    "\n",
    "## Introduccción\n",
    "\n",
    "Como ocurre en otras áreas relacionadas con la Ciencia de Datos y el Aprendizaje Automático, Python es probablemente el lenguaje de programación que tiene disponibles más herramientas para realizar tareas de Procesamiento del Lenguaje Natural. En esta nota técnica vamos a hablar de tres de ellas: [spaCy](http://www.spacy.io/), [flair](https://github.com/flairNLP/flair) y [transformers](https://huggingface.co/transformers/). \n",
    "\n",
    "\n",
    "## spaCy\n",
    "\n",
    "[spaCy](http://www.spacy.io/), de la empresa [Explosion](https://explosion.ai/), es una librería de procesamiento del lenguaje natural, de alto nivel, robusta, rápida, fácil de instalar y utilizar, e integrable con [otras librerías de *NLP* y de *deep learning*](https://spacy.io/universe). \n",
    "\n",
    "Tiene modelos entrenados en varios idiomas y permite realizar las [típicas tareas](https://spacy.io/usage/facts-figures) de segmentación por oraciones, tokenizanción, análisis morfológico, extracción de entidades y análisis de opinión. Vamos a aprender a utilizarla.\n",
    "\n",
    "### Instalamos las dependencias\n",
    "\n",
    "Lo primero que vamos a hacer es instalar la librería y [descargar un par de modelos](https://spacy.io/usage/models) que ya están entrenados y que nos van a permiter realizar tareas de PLN en inglés y español.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "  <p>Atención: Si estás ejecutando este cuaderno en local, asegúrate de que estás usando un entorno virtual.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# instalamos spacy\n",
    "!pip install -U spacy\n",
    "\n",
    "# y descargamos un par de modelos pre-entrenados para inglés y español\n",
    "!python -m spacy download es_core_news_md\n",
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentación y tokenización con spaCy\n",
    "\n",
    "Para poder utilizar spaCy, necesitamos importar la librería y crear un objeto de tipo analizador con alguno de los modelos instalados. Comencemos cargando el modelo en español."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# creamos un analizador con el modelo entrenado en español\n",
    "nlp_es = spacy.load(\"es_core_news_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para analizar cualquier texto en lenguaje natural, basta con crear un objeto de tipo documento pasándole una cadena de texto analizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"\"\"Premio Nobel de Química 2020 para Charpentier y Doudna por CRISPR. La Real Academia Sueca de Ciencias otorga el Nobel de Química a Emmanuelle Charpentier y Jennifer A. Doudna por el desarrollo de esta herramienta de edición genética. El español Francis Mojica se queda sin reconocimiento a pesar de haber descubierto el sistema CRISPR en bacterias.\"\"\"\n",
    "\n",
    "# y procesamos el texto\n",
    "doc = nlp_es(texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verás que el paso anterior no produce ninguna salida aparente. Pero ese objeto `doc` que acabamos de crear en realidad contiene mucha información resultado de ejecutar varias tareas de comprensión del lenguaje natural sobre el contenido de `texto`. En una sola línea de código hemos segmentado el texto en oraciones, hemos tokenizado las oraciones, hemos realizado el análisis morfo-sintáctico de las oraciones y hemos hecho reconocimiento de entidades.\n",
    "\n",
    "Veamos a continuación cómo podemos acceder a esa información de manera programática.\n",
    "\n",
    "Podemos iterar sobre las oraciones del documento a través de la propiedad `doc.sents`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premio Nobel de Química 2020 para Charpentier y Doudna por CRISPR.\n",
      "\n",
      "La Real Academia Sueca de Ciencias otorga el Nobel de Química a Emmanuelle Charpentier y Jennifer A. Doudna por el desarrollo de esta herramienta de edición genética.\n",
      "\n",
      "El español Francis Mojica se queda sin reconocimiento a pesar de haber descubierto el sistema CRISPR en bacterias.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for oracion in doc.sents:\n",
    "    print(f\"{oracion}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada oración está a su vez segmentada en unidades indivisibles llamados *tokens*. En este caso de spaCy, los tokens coinciden con la idea intuitiva de lo que es una palabra o un signo de puntuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La oración 1 tiene 12 tokens.\n",
      "La oración 2 tiene 28 tokens.\n",
      "La oración 3 tiene 19 tokens.\n"
     ]
    }
   ],
   "source": [
    "for n, oracion in enumerate(doc.sents):\n",
    "    print(f\"La oración {n+1} tiene {len(oracion)} tokens.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para verlo más claro y poder reutilizar el código, vamos a crear una sencilla función para tokenizar texto usando spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['¿', 'Esto', 'es', 'solo', 'una', 'texto', 'de', 'ejemplo', '?', 'Mmm', '...', '¡', 'Pues', 'parece', 'que', 'sí', '😃', '!']\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "def tokenize(text: str, model: spacy.language.Language) -> List[str]:\n",
    "    \"\"\"Returns a tokenized version of a text using a spaCy model\"\"\"\n",
    "    return [t.text for t in model(text)]\n",
    "\n",
    "print(tokenize(\"¿Esto es solo una texto de ejemplo? Mmm... ¡Pues parece que sí 😃!\", model=nlp_es))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y si probamos a tokenizar varias oraciones de ejemplo, verás que efectivamente los tokens coinciden con la idea intuitiva que tenemos en español de lo que es una palabra, un emoji o un signo de puntuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Premio', 'Nobel', 'de', 'Química', '2020', 'para', 'Charpentier', 'y', 'Doudna', 'por', 'CRISPR', '.'] \n",
      "\n",
      "['La', 'Real', 'Academia', 'Sueca', 'de', 'Ciencias', 'otorga', 'el', 'Nobel', 'de', 'Química', 'a', 'Emmanuelle', 'Charpentier', 'y', 'Jennifer', 'A.', 'Doudna', 'por', 'el', 'desarrollo', 'de', 'esta', 'herramienta', 'de', 'edición', 'genética', '.'] \n",
      "\n",
      "['El', 'español', 'Francis', 'Mojica', 'se', 'queda', 'sin', 'reconocimiento', 'a', 'pesar', 'de', 'haber', 'descubierto', 'el', 'sistema', 'CRISPR', 'en', 'bacterias', '.'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for oracion in doc.sents:\n",
    "    print(tokenize(oracion.text, model=nlp_es), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Más adelante veremos cómo es esta tokenización en inglés.\n",
    "\n",
    "### Análisis morfo-sintáctico son spaCy\n",
    "\n",
    "El documento que hemos analizado contiene completa información morfo-sintáctica de todos los tokens. ¿Qué tipo de información es esta? Veamos un ejemplo sobre una de las oraciones y [revisa la documentación del API de spaCy](https://spacy.io/api/token)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El token \"El\" ocupa la posición 40, entre los índices 234 y 236.\n",
      "Tiene como forma canónica la forma \"El\".\n",
      "Es una palabra de tipo DET con los siguientes rasgos morfológicos: DET__Definite=Def|Gender=Masc|Number=Sing|PronType=Art.\n",
      "Su función en la oración es det.\n",
      "\n",
      "El token \"español\" ocupa la posición 41, entre los índices 237 y 244.\n",
      "Tiene como forma canónica la forma \"español\".\n",
      "Es una palabra de tipo NOUN con los siguientes rasgos morfológicos: NOUN__Gender=Masc|Number=Sing.\n",
      "Su función en la oración es nsubj.\n",
      "\n",
      "El token \"Francis\" ocupa la posición 42, entre los índices 245 y 252.\n",
      "Tiene como forma canónica la forma \"Francis\".\n",
      "Es una palabra de tipo PROPN con los siguientes rasgos morfológicos: PROPN.\n",
      "Su función en la oración es appos.\n",
      "\n",
      "El token \"Mojica\" ocupa la posición 43, entre los índices 253 y 259.\n",
      "Tiene como forma canónica la forma \"Mojica\".\n",
      "Es una palabra de tipo PROPN con los siguientes rasgos morfológicos: PROPN.\n",
      "Su función en la oración es flat.\n",
      "\n",
      "El token \"se\" ocupa la posición 44, entre los índices 260 y 262.\n",
      "Tiene como forma canónica la forma \"se\".\n",
      "Es una palabra de tipo PRON con los siguientes rasgos morfológicos: PRON__Case=Acc,Dat|Person=3|PrepCase=Npr|PronType=Prs|Reflex=Yes.\n",
      "Su función en la oración es obj.\n",
      "\n",
      "El token \"queda\" ocupa la posición 45, entre los índices 263 y 268.\n",
      "Tiene como forma canónica la forma \"quedo\".\n",
      "Es una palabra de tipo VERB con los siguientes rasgos morfológicos: VERB__Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin.\n",
      "Su función en la oración es ROOT.\n",
      "\n",
      "El token \"sin\" ocupa la posición 46, entre los índices 269 y 272.\n",
      "Tiene como forma canónica la forma \"sin\".\n",
      "Es una palabra de tipo ADP con los siguientes rasgos morfológicos: ADP__AdpType=Prep.\n",
      "Su función en la oración es case.\n",
      "\n",
      "El token \"reconocimiento\" ocupa la posición 47, entre los índices 273 y 287.\n",
      "Tiene como forma canónica la forma \"reconocimiento\".\n",
      "Es una palabra de tipo NOUN con los siguientes rasgos morfológicos: NOUN__Gender=Masc|Number=Sing.\n",
      "Su función en la oración es obl.\n",
      "\n",
      "El token \"a\" ocupa la posición 48, entre los índices 288 y 289.\n",
      "Tiene como forma canónica la forma \"a\".\n",
      "Es una palabra de tipo ADP con los siguientes rasgos morfológicos: ADP__AdpType=Prep.\n",
      "Su función en la oración es mark.\n",
      "\n",
      "El token \"pesar\" ocupa la posición 49, entre los índices 290 y 295.\n",
      "Tiene como forma canónica la forma \"pesar\".\n",
      "Es una palabra de tipo INTJ con los siguientes rasgos morfológicos: NOUN.\n",
      "Su función en la oración es fixed.\n",
      "\n",
      "El token \"de\" ocupa la posición 50, entre los índices 296 y 298.\n",
      "Tiene como forma canónica la forma \"de\".\n",
      "Es una palabra de tipo ADP con los siguientes rasgos morfológicos: ADP__AdpType=Prep.\n",
      "Su función en la oración es fixed.\n",
      "\n",
      "El token \"haber\" ocupa la posición 51, entre los índices 299 y 304.\n",
      "Tiene como forma canónica la forma \"haber\".\n",
      "Es una palabra de tipo VERB con los siguientes rasgos morfológicos: AUX__VerbForm=Inf.\n",
      "Su función en la oración es aux.\n",
      "\n",
      "El token \"descubierto\" ocupa la posición 52, entre los índices 305 y 316.\n",
      "Tiene como forma canónica la forma \"descubrir\".\n",
      "Es una palabra de tipo VERB con los siguientes rasgos morfológicos: VERB__Gender=Masc|Number=Sing|Tense=Past|VerbForm=Part.\n",
      "Su función en la oración es advcl.\n",
      "\n",
      "El token \"el\" ocupa la posición 53, entre los índices 317 y 319.\n",
      "Tiene como forma canónica la forma \"el\".\n",
      "Es una palabra de tipo DET con los siguientes rasgos morfológicos: DET__Definite=Def|Gender=Masc|Number=Sing|PronType=Art.\n",
      "Su función en la oración es det.\n",
      "\n",
      "El token \"sistema\" ocupa la posición 54, entre los índices 320 y 327.\n",
      "Tiene como forma canónica la forma \"sistema\".\n",
      "Es una palabra de tipo NOUN con los siguientes rasgos morfológicos: NOUN__Gender=Masc|Number=Sing.\n",
      "Su función en la oración es obj.\n",
      "\n",
      "El token \"CRISPR\" ocupa la posición 55, entre los índices 328 y 334.\n",
      "Tiene como forma canónica la forma \"CRISPR\".\n",
      "Es una palabra de tipo PROPN con los siguientes rasgos morfológicos: PROPN.\n",
      "Su función en la oración es amod.\n",
      "\n",
      "El token \"en\" ocupa la posición 56, entre los índices 335 y 337.\n",
      "Tiene como forma canónica la forma \"en\".\n",
      "Es una palabra de tipo ADP con los siguientes rasgos morfológicos: ADP__AdpType=Prep.\n",
      "Su función en la oración es case.\n",
      "\n",
      "El token \"bacterias\" ocupa la posición 57, entre los índices 338 y 347.\n",
      "Tiene como forma canónica la forma \"bacteria\".\n",
      "Es una palabra de tipo NOUN con los siguientes rasgos morfológicos: NOUN__Gender=Fem|Number=Plur.\n",
      "Su función en la oración es obl.\n",
      "\n",
      "El token \".\" ocupa la posición 58, entre los índices 347 y 348.\n",
      "Tiene como forma canónica la forma \".\".\n",
      "Es una palabra de tipo PUNCT con los siguientes rasgos morfológicos: PUNCT__PunctType=Peri.\n",
      "Su función en la oración es punct.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tercera_oracion = list(doc.sents)[2]\n",
    "\n",
    "for token in tercera_oracion:\n",
    "    print(f\"\"\"El token \"{token}\" ocupa la posición {token.i}, entre los índices {token.idx} y {token.idx+len(token.text)}.\"\"\")\n",
    "    print(f\"\"\"Tiene como forma canónica la forma \"{token.lemma_}\".\"\"\")\n",
    "    print(f\"\"\"Es una palabra de tipo {token.pos_} con los siguientes rasgos morfológicos: {token.tag_}.\"\"\")\n",
    "    print(f\"\"\"Su función en la oración es {token.dep_}.\\n\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la celda anterior hemos impreso por pantalla toda la información relevante para describir los tokens de una de las oraciones. Estamos imprimiendo la posición y los *offsets* del token, el tipo de palabra o categoría gramatical a la que pertenece, su lema (la forma canónica bajo la que aparece en el diccionario), los rasgos morfológicos asociados (dependiendo del tipo de palabra, imprimimos el género y el número, o la persona y el tiempo, etc.) y la función que desempeña en la oración. \n",
    "\n",
    "No pretendo que conozcas el significado de toda la información que aparece, aunque algunas cosas sí es posible que te suenen de las clases de lengua. Por ejemplo, etiquetas como `DET`, `NOUN`, `VERB`, y `PROPN` se utilizan para describir respectivamente determinantes, nombres comunes, verbos y nombres propios. Los rasgos `Gender=Masc|Number=Sing|Tense=Past|VerbForm=Part` describen un token como forma verbal de tipo participio, género másculino, número singular, tiempo pasado.\n",
    "\n",
    "Sí es importante que sepas que estas etiquetas están diseñadas para describir la morfología y la sintaxis de muchas lenguas del mundo y que siguen las convenciones habituales en el ámbito de la lingüística y el PLN que se recogen bajo el proyecto [Universal Dependencies](https://universaldependencies.org/guidelines.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconocimiento de entidades con spaCy\n",
    "\n",
    "El texto que hemos analizado contenía varias entidades nombradas, esto es menciones a personas, organizaciones y lugares. Te en cuenta que algunas menciones pueden tener más de un token. Veamos cómo podemos acceder a ellas a través de la propiedad `doc.ents`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El documento analizado contiene 10 entidades.\n",
      "\n",
      "  1. La mención \"Premio Nobel de Química 2020\" es de tipo MISC, y ocupa los tokens 0-5.\n",
      "  2. La mención \"Charpentier\" es de tipo PER, y ocupa los tokens 6-7.\n",
      "  3. La mención \"Doudna\" es de tipo PER, y ocupa los tokens 8-9.\n",
      "  4. La mención \"CRISPR\" es de tipo ORG, y ocupa los tokens 10-11.\n",
      "  5. La mención \"Real Academia Sueca de Ciencias\" es de tipo ORG, y ocupa los tokens 13-18.\n",
      "  6. La mención \"Nobel de Química\" es de tipo ORG, y ocupa los tokens 20-23.\n",
      "  7. La mención \"Emmanuelle Charpentier\" es de tipo PER, y ocupa los tokens 24-26.\n",
      "  8. La mención \"Jennifer A. Doudna\" es de tipo PER, y ocupa los tokens 27-30.\n",
      "  9. La mención \"Francis Mojica\" es de tipo PER, y ocupa los tokens 42-44.\n",
      "  10. La mención \"CRISPR\" es de tipo MISC, y ocupa los tokens 55-56.\n"
     ]
    }
   ],
   "source": [
    "print(f\"El documento analizado contiene {len(doc.ents)} entidades.\\n\")\n",
    "\n",
    "for n, entidad in enumerate(doc.ents):\n",
    "    print(f\"\"\"  {n+1}. La mención \"{entidad}\" es de tipo {entidad.label_}, y ocupa los tokens {entidad.start}-{entidad.end}.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El [modelo en español que estamos utilizando](https://spacy.io/models/es#es_core_news_md) es capaz de identificar solo cuatro tipos de entidades distintos: personas (`PER`), organizaciones (`ORG`), lugares (`LOC`) y entidades de otros tipos que se engloban dentro de la categoría `MISC`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La propia librería contiene [varias maneras de visualizar el análisis del documento](https://spacy.io/usage/visualizers), como se muestra en el reconocimiento de entidades de la celda siguiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"es\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Premio Nobel de Química 2020\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " para \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Charpentier\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " y \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Doudna\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " por \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    CRISPR\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ". La \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Real Academia Sueca de Ciencias\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " otorga el \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Nobel de Química\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " a \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Emmanuelle Charpentier\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " y \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Jennifer A. Doudna\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " por el desarrollo de esta herramienta de edición genética. El español \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Francis Mojica\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " se queda sin reconocimiento a pesar de haber descubierto el sistema \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    CRISPR\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " en bacterias.</div>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'ent' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.serve(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando spaCy con otras lenguas\n",
    "\n",
    "Hasta ahora hemos utilizado un modelo que ha sido entrenado con colleciones de datos en español. No solo eso, si profundizas en la documentación de los modelos disponibles en spaCy, descubrirás que [este modelo se llama precisamente `es_core_news_md`](https://spacy.io/models/es#es_core_news_md) porque está entrenado con datos en español (`es`), sobre colecciones de noticias (`news`) y de los tres tamaños disponibles este es el mediano (`md`).\n",
    "\n",
    "El tamaño del modelo determina el rendimiento final. A *grosso modo*, cuanto más grande sea, mejor calidad tendrá, aunque será más pesado y complejo de manejar. El origen de los datos también hay que tenerlo en cuenta. Los textos provenientes de medios de comunicación de masas y noticias contienen ejemplos de lengua en su variante culta. Esto significa que funcionarán muy bien para analizar texto de las mismas características, pero que probablemente funcionen mal si queremos procesar textos que usen la variante coloquial de la lengua o registros no estándar, que es lo que ocurre en redes sociales o con la mensajería instatánea. Mucho cuidado con usar modelos de PLN entrenados con noticias para tratar analizar mensajes de chat entre adolescentes. No van a a funcionar bien.\n",
    "\n",
    "En cualquier caso, en spaCy tenemos disponibles otros modelos entreandos para otras lenguas. Por ejemplo, el modelo que cargamos a continuación es de tamaño mediano (`md`), está entrenado con datos en inglés (`en`), con documentos provenientes de la páginas web, blogs, y comentarios de usuarios (`web`). *A priori*, este modelo debería funcionar mejor para analizar lengua no culta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_en = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mismo código que hemos usado en las celdas anteriores sirve para procesar un texto en inglés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"A trade war between the world's two largest economies officially began on Friday morning. The Trump administration followed through with its threat to impose tariffs on $34 billion worth of Chinese products, a significant escalation of a fight that could hurt companies and consumers in both the United States and China.\"\"\"\n",
    "\n",
    "# y procesamos el texto\n",
    "doc_en = nlp_en(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos segmentar en oraciones y tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A trade war between the world's two largest economies officially began on Friday morning.\n",
      "\n",
      "The Trump administration followed through with its threat to impose tariffs on $34 billion worth of Chinese products, a significant escalation of a fight that could hurt companies and consumers in both the United States and China.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for oracion in doc_en.sents:\n",
    "    print(f\"{oracion}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La oración 1 tiene 16 tokens.\n",
      "La oración 2 tiene 40 tokens.\n"
     ]
    }
   ],
   "source": [
    "for n, oracion in enumerate(doc_en.sents):\n",
    "    print(f\"La oración {n+1} tiene {len(oracion)} tokens.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a recuperar la función para tokenizar texto que hemos definido más arriba. ¿Cómo son los tokens que segmenta spaCy cuando la lengua es el inglés?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'trade', 'war', 'between', 'the', 'world', \"'s\", 'two', 'largest', 'economies', 'officially', 'began', 'on', 'Friday', 'morning', '.'] \n",
      "\n",
      "['The', 'Trump', 'administration', 'followed', 'through', 'with', 'its', 'threat', 'to', 'impose', 'tariffs', 'on', '$', '34', 'billion', 'worth', 'of', 'Chinese', 'products', ',', 'a', 'significant', 'escalation', 'of', 'a', 'fight', 'that', 'could', 'hurt', 'companies', 'and', 'consumers', 'in', 'both', 'the', 'United', 'States', 'and', 'China', '.'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for oracion in doc_en.sents:\n",
    "    print(tokenize(oracion.text, model=nlp_en), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quizá lo más llamativo es que en inglés se tokenizan algunas formas verbales que llevan contracciones, los genitivos sajón y algunos símbolos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['You', \"'d\", 'better', 'go', 'with', 'those', '$', '1000', '!', 'You', 'are', \"n't\", 'as', 'smart', 'as', 'you', 'think', '.']\n"
     ]
    }
   ],
   "source": [
    "print(tokenize(\"You'd better go with those $1000! You aren't as smart as you think.\", model=nlp_en))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hemos visto antes, el objeto `doc_en` también contiene el análisis morfo-sintáctico del texto. Imprimamos el de la primera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El token \"A\" ocupa la posición 0, entre los índices 0 y 1.\n",
      "Tiene como forma canónica la forma \"a\".\n",
      "Es una palabra de tipo DET con los siguientes rasgos morfológicos: DT.\n",
      "Su función en la oración es det.\n",
      "\n",
      "El token \"trade\" ocupa la posición 1, entre los índices 2 y 7.\n",
      "Tiene como forma canónica la forma \"trade\".\n",
      "Es una palabra de tipo NOUN con los siguientes rasgos morfológicos: NN.\n",
      "Su función en la oración es compound.\n",
      "\n",
      "El token \"war\" ocupa la posición 2, entre los índices 8 y 11.\n",
      "Tiene como forma canónica la forma \"war\".\n",
      "Es una palabra de tipo NOUN con los siguientes rasgos morfológicos: NN.\n",
      "Su función en la oración es nsubj.\n",
      "\n",
      "El token \"between\" ocupa la posición 3, entre los índices 12 y 19.\n",
      "Tiene como forma canónica la forma \"between\".\n",
      "Es una palabra de tipo ADP con los siguientes rasgos morfológicos: IN.\n",
      "Su función en la oración es prep.\n",
      "\n",
      "El token \"the\" ocupa la posición 4, entre los índices 20 y 23.\n",
      "Tiene como forma canónica la forma \"the\".\n",
      "Es una palabra de tipo DET con los siguientes rasgos morfológicos: DT.\n",
      "Su función en la oración es det.\n",
      "\n",
      "El token \"world\" ocupa la posición 5, entre los índices 24 y 29.\n",
      "Tiene como forma canónica la forma \"world\".\n",
      "Es una palabra de tipo NOUN con los siguientes rasgos morfológicos: NN.\n",
      "Su función en la oración es poss.\n",
      "\n",
      "El token \"'s\" ocupa la posición 6, entre los índices 29 y 31.\n",
      "Tiene como forma canónica la forma \"'s\".\n",
      "Es una palabra de tipo PART con los siguientes rasgos morfológicos: POS.\n",
      "Su función en la oración es case.\n",
      "\n",
      "El token \"two\" ocupa la posición 7, entre los índices 32 y 35.\n",
      "Tiene como forma canónica la forma \"two\".\n",
      "Es una palabra de tipo NUM con los siguientes rasgos morfológicos: CD.\n",
      "Su función en la oración es nummod.\n",
      "\n",
      "El token \"largest\" ocupa la posición 8, entre los índices 36 y 43.\n",
      "Tiene como forma canónica la forma \"large\".\n",
      "Es una palabra de tipo ADJ con los siguientes rasgos morfológicos: JJS.\n",
      "Su función en la oración es amod.\n",
      "\n",
      "El token \"economies\" ocupa la posición 9, entre los índices 44 y 53.\n",
      "Tiene como forma canónica la forma \"economy\".\n",
      "Es una palabra de tipo NOUN con los siguientes rasgos morfológicos: NNS.\n",
      "Su función en la oración es pobj.\n",
      "\n",
      "El token \"officially\" ocupa la posición 10, entre los índices 54 y 64.\n",
      "Tiene como forma canónica la forma \"officially\".\n",
      "Es una palabra de tipo ADV con los siguientes rasgos morfológicos: RB.\n",
      "Su función en la oración es advmod.\n",
      "\n",
      "El token \"began\" ocupa la posición 11, entre los índices 65 y 70.\n",
      "Tiene como forma canónica la forma \"begin\".\n",
      "Es una palabra de tipo VERB con los siguientes rasgos morfológicos: VBD.\n",
      "Su función en la oración es ROOT.\n",
      "\n",
      "El token \"on\" ocupa la posición 12, entre los índices 71 y 73.\n",
      "Tiene como forma canónica la forma \"on\".\n",
      "Es una palabra de tipo ADP con los siguientes rasgos morfológicos: IN.\n",
      "Su función en la oración es prep.\n",
      "\n",
      "El token \"Friday\" ocupa la posición 13, entre los índices 74 y 80.\n",
      "Tiene como forma canónica la forma \"Friday\".\n",
      "Es una palabra de tipo PROPN con los siguientes rasgos morfológicos: NNP.\n",
      "Su función en la oración es compound.\n",
      "\n",
      "El token \"morning\" ocupa la posición 14, entre los índices 81 y 88.\n",
      "Tiene como forma canónica la forma \"morning\".\n",
      "Es una palabra de tipo NOUN con los siguientes rasgos morfológicos: NN.\n",
      "Su función en la oración es pobj.\n",
      "\n",
      "El token \".\" ocupa la posición 15, entre los índices 88 y 89.\n",
      "Tiene como forma canónica la forma \".\".\n",
      "Es una palabra de tipo PUNCT con los siguientes rasgos morfológicos: ..\n",
      "Su función en la oración es punct.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "primera_oracion = list(doc_en.sents)[0]\n",
    "\n",
    "for token in primera_oracion:\n",
    "    print(f\"\"\"El token \"{token}\" ocupa la posición {token.i}, entre los índices {token.idx} y {token.idx+len(token.text)}.\"\"\")\n",
    "    print(f\"\"\"Tiene como forma canónica la forma \"{token.lemma_}\".\"\"\")\n",
    "    print(f\"\"\"Es una palabra de tipo {token.pos_} con los siguientes rasgos morfológicos: {token.tag_}.\"\"\")\n",
    "    print(f\"\"\"Su función en la oración es {token.dep_}.\\n\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si te fijas en la salida de este análisis y lo comparas con el del español, es probable que te llamen la atención varias cosas.\n",
    "\n",
    "- El análisis no contiene rasgos morfológicos. Esto ocurre porque el inglés tiene una variación morfológica muy pobre (comparada con el español y otras lenguas). Si lo piensas un poco, los nombres en inglés no tienen marca de género, los adjetivos no distinguen entre singular y plural, y la conjugación de los verbos es muy sencilla.\n",
    "\n",
    "- El análisis morfo-sintáctico en inglés muestra otras etiquetas. Ahora los determinantes, los nombres, los nombres propios y los vebos se anotan como `DT`, `NN` o `NNS`, `NNP` y `VB*`. ¿Por qué pasa esto? Precisamente, por las características de la lengua inglesa, tiene sentido utilizar un esquema específico adaptado a su vocabulario. El modelo en inglés que estamos usando ha sido entrenado de manera supervisada con datos que contienen otro tipo de anotaciones. Si tienes curiosidad en profundizar en este otro *tagset*, el conjunto de etiquetas que aquí aparece es muy conocido en el mundo del PLN porque fue el primero, y se denomina [etiquetas del corpus de Brown](https://en.wikipedia.org/wiki/Brown_Corpus#Part-of-speech_tags_used).\n",
    "\n",
    "Por último, también podemos extraer y visualizar las entidades nombradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El documento analizado contiene 7 entidades.\n",
      "\n",
      "  1. La mención \"two\" es de tipo CARDINAL, y ocupa los tokens 7-8.\n",
      "  2. La mención \"Friday morning\" es de tipo TIME, y ocupa los tokens 13-15.\n",
      "  3. La mención \"Trump\" es de tipo ORG, y ocupa los tokens 17-18.\n",
      "  4. La mención \"$34 billion\" es de tipo MONEY, y ocupa los tokens 28-31.\n",
      "  5. La mención \"Chinese\" es de tipo NORP, y ocupa los tokens 33-34.\n",
      "  6. La mención \"the United States\" es de tipo GPE, y ocupa los tokens 50-53.\n",
      "  7. La mención \"China\" es de tipo GPE, y ocupa los tokens 54-55.\n"
     ]
    }
   ],
   "source": [
    "print(f\"El documento analizado contiene {len(doc_en.ents)} entidades.\\n\")\n",
    "\n",
    "for n, entidad in enumerate(doc_en.ents):\n",
    "    print(f\"\"\"  {n+1}. La mención \"{entidad}\" es de tipo {entidad.label_}, y ocupa los tokens {entidad.start}-{entidad.end}.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">A trade war between the world's \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    two\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " largest economies officially began on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Friday morning\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
       "</mark>\n",
       ". The \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Trump\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " administration followed through with its threat to impose tariffs on \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $34 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       " worth of \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Chinese\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " products, a significant escalation of a fight that could hurt companies and consumers in both \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the United States\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    China\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ".</div>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'ent' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.serve(doc_en, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí también hay algunas diferencias que habrás notado con respecto al modelo en español. En este caso, el modelo utiliza otros identificadores diferentes para las entidades y es capaz de reconocer más tipos de entidades diferentes. Y en general, funciona mejor que el del español. Esto ocurre básicamente porque [este modelo en inglés](https://spacy.io/models/en#en_core_web_md), tal y como se describe en la documentación de spaCy, ha sido entrenado con un dataset más grande llamado [OntoNotes](https://catalog.ldc.upenn.edu/LDC2013T19).\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "  <p>Como en otros ámbitos que utilizan aproximaciones basadas en aprendizaje automático y <i>deep learning</i>, el rendikiento de un sistema depende más de los datos que del algoritmo que hay detrás. En este caso, los datasets disponibles para el inglés son notablemente mayores y de mayor calidad que los disponibles en otras lenguas.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flair\n",
    "\n",
    "[flair](https://github.com/flairNLP/flair) es una librería de PLN de software libre desarrollada inicialmente por la división de ingeniería de Zalando y basada en PyTorch. Permite acceder a funcionalidades muy interesantes para procesar lenguaje natural, algunas de ellas con aproximaciones muy modernas:\n",
    "\n",
    "- segmentar el texto y [realizar operaciones básicas con lenguaje natural](https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_1_BASICS.md)\n",
    "- etiquetar texto en lenguaje natural con modelos preentrenados con [información morfo-sintáctica, de entidades nombradas](https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_2_TAGGING.md)\n",
    "- clasificar automáticamente texto\n",
    "- entrenar tus propios modelos para [construir otros clasificadores](https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_7_TRAINING_A_MODEL.md)\n",
    "- [representar las palabras como *embeddings*](https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_3_WORD_EMBEDDING.md) de distintos tipos\n",
    "\n",
    "Veamos cómo podemos acceder a algunas de sus funcionalidades, pero lo primero es asegurarnos de que tenemos la librería instalada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instalamos flair\n",
    "!pip install -U flair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis morfológico con flair\n",
    "\n",
    "El API de flair es diferente al que hemos visto en spaCy. En lugar de importar un único modelo pre-entrenado capaz de maneajar todos los aspectos de una lengua, con flair tendremos que instanciar determinadas clases para representar las oraciones y el modelo que queremos utilizar, en función del tipo de tarea de PLN que queramos resolver. \n",
    "\n",
    "Por ejemplo, para analizar sintácticamente un texto con flair, necesitamos es importar dos cosas: \n",
    "\n",
    "1. una  la clase `Sentence`, que nos permite representar una secuencia de texto en lenguaje natural con sentido completo, \n",
    "2. como la tarea que queremos resolver implica procesar y etiquetar secuencias ordenadas de tokens, necesitamos importar un `SequenceTagger` y construirlo con un modelo específico capaz de manejar información morfológica. \n",
    "\n",
    "[Hay varios modelos disponibles](https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_2_TAGGING.md#list-of-pre-trained-sequence-tagger-models), pero en este ejemplo vamos a utilizar uno pre-entrenado para reconocer las categorías gramaticales en varios idiomas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-01 18:53:21,342 loading file /home/victor/.flair/models/pos-multi-fast.pt\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "# cargamos el analizador con un modelo multi-idioma en su versión fast, que funciona en CPU\n",
    "# la primera vez que intentas cargar un modelo tendrás que descargalo \n",
    "tagger = SequenceTagger.load(\"pos-multi-fast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "  <p>Si tienes acceso a GPU, a través de <a href=\"https://colab.research.google.com/\" target=\"_blank\">Google Colab</a>, por ejemplo, no dudes en utilizar la versión completa y cargar el modelo llamado<code>pos-multi</code>.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facebook <PROPN> nació <VERB> hace <VERB> década <NOUN> y <CCONJ> media <NOUN> tras <ADP> una <DET> noche <NOUN> de <ADP> copas <NOUN> de <ADP> Mark <PROPN> Zuckerberg <PROPN> . <PUNCT> \n",
      "\n",
      "Grand <ADJ> débat <NOUN> national <ADJ> : <PUNCT> suivez <VERB> Emmanuel <PROPN> Macron <PROPN> en <ADP> direct <NOUN> de <ADP> Bordeaux <PROPN> . <PUNCT> \n",
      "\n",
      "Hier <ADV> an <ADP> der <DET> Zufahrt <NOUN> zur <ADP> Startrampe <NOUN> 39A <PROPN> , <PUNCT> wo <ADV> vor <ADP> 50 <NUM> Jahren <NOUN> die <DET> gigantischen <ADJ> Saturn-Raketen <NOUN> der <DET> Apollo-Mondmissionen <NOUN> im <ADJ> Schneckentempo <NOUN> vorbeigefahren <VERB> sind <AUX> , <PUNCT> prangen <VERB> nun <ADV> die <DET> blauen <ADJ> Lettern <NOUN> des <DET> Raumfahrtunternehmens <NOUN> von <ADP> Elon <PROPN> Musk <PROPN> an <ADP> einem <DET> Hangar <NOUN> . <PUNCT> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "oracion_es = Sentence(\"Facebook nació hace década y media tras una noche de copas de Mark Zuckerberg.\")\n",
    "tagger.predict(oracion_es)\n",
    "# imprimimos el análisis\n",
    "print(oracion_es.to_tagged_string(), \"\\n\")\n",
    "\n",
    "oracion_fr = Sentence(\"Grand débat national: suivez Emmanuel Macron en direct de Bordeaux.\")\n",
    "tagger.predict(oracion_fr)\n",
    "# imprimimos el análisis\n",
    "print(oracion_fr.to_tagged_string(), \"\\n\")\n",
    "\n",
    "oracion_de = Sentence(\"Hier an der Zufahrt zur Startrampe 39A, wo vor 50 Jahren die gigantischen Saturn-Raketen der Apollo-Mondmissionen im Schneckentempo vorbeigefahren sind, prangen nun die blauen Lettern des Raumfahrtunternehmens von Elon Musk an einem Hangar.\")\n",
    "tagger.predict(oracion_de)\n",
    "# imprimimos el análisis\n",
    "print(oracion_de.to_tagged_string(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La salida de este etiquetador morfológico es bastante sencilla, solo imprime el nombre de la categoría gramatical, pero este modelo es capaz de reconocer clases de palabras en varias lenguas. Si te fijas, las etiquetas son las mismas que las utilizadas en [Universal Dependencies](https://universaldependencies.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Reconocimiento de entidades con flair\n",
    "\n",
    "El reconocimiento de entidades también es una tarea que implica procesar un texto como una secuencia ordenada de tokens. En este caso, necesitamos instanciar otro `SequenceTagger` con el modelo específico para reconocer entidades en inglés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-01 18:53:23,302 loading file /home/victor/.flair/models/en-ner-fast-conll03-v0.4.pt\n"
     ]
    }
   ],
   "source": [
    "# cargamos el modelo entrenado para reconocer de entidades\n",
    "# recuerda, NER -> named entities recognition\n",
    "tagger = SequenceTagger.load(\"ner-fast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Behind closed doors , freshman Rep <S-MISC> . Alexandria <B-PER> Ocasio <I-PER> Cortez <E-PER> threatened the Senate <S-ORG> of the United <B-LOC> States <E-LOC> to put those voting with Republicans <S-MISC> \" on a list \" for a primary challenge in the 2020 election .\n"
     ]
    }
   ],
   "source": [
    "# analizamos una oración\n",
    "oracion = Sentence(\"\"\"Behind closed doors, freshman Rep. Alexandria Ocasio Cortez threatened the Senate of the United States to put those voting with Republicans \"on a list\" for a primary challenge in the 2020 election.\"\"\")\n",
    "tagger.predict(oracion)\n",
    "# imprimimos el análisis\n",
    "print(oracion.to_tagged_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La prestas atención a la salida impresa de este análisis, verás que contiene los tokens de la oración y solo aquellas menciones identificadas como entidades nombradas imprimirán información adicional. Pero, ¿cómo se codifica e interpreta esta salida?\n",
    "\n",
    "El esquema de anotación que utiliza flair en este ejemplo es bastante habitual en tareas de reconocimiento de entidades y se denomina [esquema IOB (Inside-Outside-Beginning)](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)). \n",
    "\n",
    "Como ya sabes, un reconocedor de entidades generalista normalmente identificará varios tipos de entidades diferentes: personas (`PER`), organizaciones (`ORG`), lugares (`LOC`) y otras entidades (`MISC`). Y como hemos visto antes, las menciones de las entidades nombradas pueden expandirse a lo largo de más de un token. Pues bien, este esquema de anotación especifica con prefijos si el token en cuestión es el primer elemento de la mención (*beginning*: `B-`), si es un token dentro de la mención (*inside*: `I-`), si es el último elemento de la mención (*end*: `E-`), o si la entidad tiene un solo token (*single*: `S-`). De este modo, `Alexandria <B-PER> Ocasio <I-PER> Cortez <E-PER>` permite describir una entidad de tipo persona con tres tokens, `United <B-LOC> States <E-LOC>` es una entidad de tipo lugar con dos tokens, y `Republicans <S-MISC>` es una entidad de tipo indeterminado formada por un solo token.\n",
    "\n",
    "De manera programática, puedes acceder a la información completa de las entidades como se muestra en el siguiente ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La entidad \"Rep\" ocupa los tokens [6] y los offsets 30 y 33.\n",
      "Pertenece a la categoria MISC con una probabilidad de 0.9307801723480225.\n",
      "\n",
      "La entidad \"Alexandria Ocasio Cortez\" ocupa los tokens [8, 9, 10] y los offsets 35 y 59.\n",
      "Pertenece a la categoria PER con una probabilidad de 0.9782136678695679.\n",
      "\n",
      "La entidad \"Senate\" ocupa los tokens [13] y los offsets 75 y 81.\n",
      "Pertenece a la categoria ORG con una probabilidad de 0.9942795038223267.\n",
      "\n",
      "La entidad \"United States\" ocupa los tokens [16, 17] y los offsets 89 y 102.\n",
      "Pertenece a la categoria LOC con una probabilidad de 0.9732602536678314.\n",
      "\n",
      "La entidad \"Republicans\" ocupa los tokens [23] y los offsets 128 y 139.\n",
      "Pertenece a la categoria MISC con una probabilidad de 0.9998949766159058.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# iteramos por la entidades\n",
    "for entidad in oracion.get_spans(\"ner\"):\n",
    "    print(f\"\"\"La entidad \"{entidad.text}\" ocupa los tokens {[t.idx for t in entidad.tokens]} y los offsets {entidad.start_pos} y {entidad.end_pos}.\"\"\")\n",
    "    print(f\"\"\"Pertenece a la categoria {entidad.tag} con una probabilidad de {entidad.score}.\\n\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Behind closed doors, freshman Rep. Alexandria Ocasio Cortez threatened the Senate of the United States to put those voting with Republicans \"on a list\" for a primary challenge in the 2020 election.', 'labels': [], 'entities': [{'text': 'Rep', 'start_pos': 30, 'end_pos': 33, 'labels': [MISC (0.9308)]}, {'text': 'Alexandria Ocasio Cortez', 'start_pos': 35, 'end_pos': 59, 'labels': [PER (0.9782)]}, {'text': 'Senate', 'start_pos': 75, 'end_pos': 81, 'labels': [ORG (0.9943)]}, {'text': 'United States', 'start_pos': 89, 'end_pos': 102, 'labels': [LOC (0.9733)]}, {'text': 'Republicans', 'start_pos': 128, 'end_pos': 139, 'labels': [MISC (0.9999)]}]}\n"
     ]
    }
   ],
   "source": [
    "# o imprimimos la estructura de datos con el análisis completo\n",
    "print(oracion.to_dict(tag_type=\"ner\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Análisis de opinión con flair\n",
    "\n",
    "Otra interesante característica de flair es que nos da acceso a modelos entrenados con información sobre análisis de opinión, que permiten detectar opiniones positivas y negativas.\n",
    "\n",
    "En este caso, la tarea de análisis de opinión es un problema de claficación de texto, no de etiquetado por secuencia. Necesitaremos instanciar un objeto diferente: un `TextClassifier`, como se muestra en el siguiente ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-01 18:53:26,103 loading file /home/victor/.flair/models/sentiment-en-mix-distillbert_3.1.pt\n"
     ]
    }
   ],
   "source": [
    "from flair.models import TextClassifier\n",
    "\n",
    "classifier = TextClassifier.load(\"en-sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La oración \"I love ice-cream!\" \n",
      "contiene una opinión de tipo POSITIVE con una probabilidad de 1.00\n",
      "\n",
      "La oración \"Don't ever go to this restaurant. The food was horrible :-(\" \n",
      "contiene una opinión de tipo NEGATIVE con una probabilidad de 1.00\n",
      "\n",
      "La oración \"Evil Corp to announce job cuts.\" \n",
      "contiene una opinión de tipo NEGATIVE con una probabilidad de 1.00\n",
      "\n",
      "La oración \"What a wonderful world!\" \n",
      "contiene una opinión de tipo POSITIVE con una probabilidad de 1.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# definimos unas cuantas oraciones en inglés\n",
    "oraciones = [\"I love ice-cream!\", \"Don't ever go to this restaurant. The food was horrible :-(\", \"Evil Corp to announce job cuts.\", \"What a wonderful world!\"]\n",
    "\n",
    "for oracion in oraciones:\n",
    "    s = Sentence(oracion)\n",
    "    classifier.predict(s)\n",
    "    polaridad, prob = s.labels[0].value, s.labels[0].score\n",
    "\n",
    "    print(f\"\"\"La oración \"{s.to_plain_string()}\" \"\"\")\n",
    "    print(f\"contiene una opinión de tipo {polaridad} con una probabilidad de {prob:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transformers\n",
    "\n",
    "[transformers](https://github.com/huggingface/transformers), liderada por la empresa [HuggingFace](https://huggingface.co/), se ha convertido en los últimos años en una las librerías para tareas de NLU y NLG más importantes. En un primer momento surgió como un punto intermedio que permitía integrar en código de PyTorch modelos entrenados originalmente en TensorFlow. Actualmente, da acceso a [multitud de modelos pre-entrenados con un mismo API](https://huggingface.co/models) y está en continua evolución, dado que cuenta con una comunidad de usuarios muy activa. \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "  <p>Si tienes curiosidad en profundizar, el nombre de esta librería hace referencia a <a href=\"https://jalammar.github.io/illustrated-transformer\" target=\"_blank\">Transformer</a>, una popular arquitectura de <em>deep learning</em> que utiliza <a href=\"https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/\" target=\"_blank\">un mecanismo denominado <strong>atención</strong></a>, y que ha revolucionado el mundo del procesamiento del lenguaje natural.</p>\n",
    "</div>\n",
    "\n",
    "La [documentación de transformers es muy completa](https://huggingface.co/transformers/) y el alcance de la herramienta es muy amplio. Para el objetivo de nuestra asignatura, nos contentaremos con entender cómo podemos utilizar los modelos con uno de los interfaces de más alto nivel: [los *pipelines*](https://huggingface.co/transformers/main_classes/pipelines.html). ¡Vamos allá!\n",
    "\n",
    "Lo primero es instalar la librería."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instalamos flair\n",
    "!pip install -U transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "El objeto `pipeline` es una abstracción que nos permite especifcar la tarea de PLN y cargar cualquier modelo pre-entrenado que esté disponible en nuestra máquina local o en [el registro de modelos públicos de huggingFace](https://huggingface.co/models).\n",
    "\n",
    "Podemos crear un *pipeline* de varias maneras pero la forma más sencilla es especificando el tipo de tarea y el modelo que queremos utilizar.\n",
    "\n",
    "### Reconocimiento de entidades con transformers\n",
    "\n",
    "Para realizar reconocimiento de entidades en español, necesitamos encontrar un modelo adecuado para la tarea y el idioma. Si buscamos [modelos pre-entrenados para NER en español](https://huggingface.co/models?filter=es&search=ner) encontraremos varios de ellos. Muy probablemente estos nombres no te dirán nada, pero no abrumes, te aseguro que siguen una nomenclatura bastante habitual en el mundillo. \n",
    "\n",
    "Por ejemplo, el modelo llamado [`mrm8488/bert-spanish-cased-finetuned-ner`](https://huggingface.co/mrm8488/bert-spanish-cased-finetuned-ner) lo ha entrenado un famoso miembro de la comunidad de HuggingFace llamado [`@mrm8488`](https://twitter.com/mrm8488), ajustando para reconocimiento de entidades (haciendo *fine tune* para NER en español) un modelo BERT que distingue mayúsculas (*cased*). En cualquier caso, siempre puedes [acceder a una pequeña ficha con información extra, métricas de evaluación y ejemplos de uso](https://huggingface.co/mrm8488/bert-spanish-cased-finetuned-ner).\n",
    "\n",
    "Vamos a ver qué tal funciona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner_es_classifier = pipeline(\"ner\", model=\"mrm8488/bert-spanish-cased-finetuned-ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'word': 'Premio',\n",
       "  'score': 0.9974514245986938,\n",
       "  'entity': 'B-MISC',\n",
       "  'index': 1},\n",
       " {'word': 'Nobel',\n",
       "  'score': 0.9970600008964539,\n",
       "  'entity': 'I-MISC',\n",
       "  'index': 2},\n",
       " {'word': 'de', 'score': 0.9981623888015747, 'entity': 'I-MISC', 'index': 3},\n",
       " {'word': 'Química',\n",
       "  'score': 0.9982280731201172,\n",
       "  'entity': 'I-MISC',\n",
       "  'index': 4},\n",
       " {'word': '2020', 'score': 0.922611653804779, 'entity': 'I-MISC', 'index': 5},\n",
       " {'word': 'Char', 'score': 0.9955931305885315, 'entity': 'B-PER', 'index': 7},\n",
       " {'word': '##pent',\n",
       "  'score': 0.6227113604545593,\n",
       "  'entity': 'B-PER',\n",
       "  'index': 8},\n",
       " {'word': '##ier', 'score': 0.5794926881790161, 'entity': 'B-PER', 'index': 9},\n",
       " {'word': 'Do', 'score': 0.9936509132385254, 'entity': 'B-PER', 'index': 11},\n",
       " {'word': '##ud', 'score': 0.5442298054695129, 'entity': 'I-PER', 'index': 12},\n",
       " {'word': '##na', 'score': 0.938393771648407, 'entity': 'I-PER', 'index': 13},\n",
       " {'word': 'CR', 'score': 0.9774543046951294, 'entity': 'B-MISC', 'index': 15},\n",
       " {'word': '##IS',\n",
       "  'score': 0.5223162174224854,\n",
       "  'entity': 'I-MISC',\n",
       "  'index': 16},\n",
       " {'word': 'La', 'score': 0.8818917870521545, 'entity': 'B-ORG', 'index': 19},\n",
       " {'word': 'Real', 'score': 0.5371993780136108, 'entity': 'B-ORG', 'index': 20},\n",
       " {'word': 'Academia',\n",
       "  'score': 0.9987961053848267,\n",
       "  'entity': 'I-ORG',\n",
       "  'index': 21},\n",
       " {'word': 'Sue', 'score': 0.999445915222168, 'entity': 'I-ORG', 'index': 22},\n",
       " {'word': '##ca', 'score': 0.9994853138923645, 'entity': 'I-ORG', 'index': 23},\n",
       " {'word': 'de', 'score': 0.9995753169059753, 'entity': 'I-ORG', 'index': 24},\n",
       " {'word': 'Ciencias',\n",
       "  'score': 0.9994133114814758,\n",
       "  'entity': 'I-ORG',\n",
       "  'index': 25},\n",
       " {'word': 'Nobel',\n",
       "  'score': 0.9944096207618713,\n",
       "  'entity': 'B-MISC',\n",
       "  'index': 28},\n",
       " {'word': 'de', 'score': 0.9756442904472351, 'entity': 'I-MISC', 'index': 29},\n",
       " {'word': 'Química',\n",
       "  'score': 0.986515998840332,\n",
       "  'entity': 'I-MISC',\n",
       "  'index': 30},\n",
       " {'word': 'Emma', 'score': 0.9997843503952026, 'entity': 'B-PER', 'index': 32},\n",
       " {'word': '##nu', 'score': 0.9926055073738098, 'entity': 'I-PER', 'index': 33},\n",
       " {'word': '##elle',\n",
       "  'score': 0.997874915599823,\n",
       "  'entity': 'I-PER',\n",
       "  'index': 34},\n",
       " {'word': 'Char', 'score': 0.9996539354324341, 'entity': 'I-PER', 'index': 35},\n",
       " {'word': '##pent',\n",
       "  'score': 0.9994781613349915,\n",
       "  'entity': 'I-PER',\n",
       "  'index': 36},\n",
       " {'word': '##ier',\n",
       "  'score': 0.9987934231758118,\n",
       "  'entity': 'I-PER',\n",
       "  'index': 37},\n",
       " {'word': '[UNK]',\n",
       "  'score': 0.9997192025184631,\n",
       "  'entity': 'B-PER',\n",
       "  'index': 39},\n",
       " {'word': 'A', 'score': 0.9997491836547852, 'entity': 'I-PER', 'index': 40},\n",
       " {'word': '.', 'score': 0.9985464215278625, 'entity': 'I-PER', 'index': 41},\n",
       " {'word': 'Do', 'score': 0.9995366334915161, 'entity': 'I-PER', 'index': 42},\n",
       " {'word': '##ud', 'score': 0.9993067979812622, 'entity': 'I-PER', 'index': 43},\n",
       " {'word': '##na', 'score': 0.9977015852928162, 'entity': 'I-PER', 'index': 44},\n",
       " {'word': 'Francis',\n",
       "  'score': 0.9998371601104736,\n",
       "  'entity': 'B-PER',\n",
       "  'index': 57},\n",
       " {'word': 'Mo', 'score': 0.999780535697937, 'entity': 'I-PER', 'index': 58},\n",
       " {'word': '##ji', 'score': 0.9997037053108215, 'entity': 'I-PER', 'index': 59},\n",
       " {'word': '##ca', 'score': 0.9996520280838013, 'entity': 'I-PER', 'index': 60},\n",
       " {'word': 'CR', 'score': 0.994926393032074, 'entity': 'B-MISC', 'index': 72},\n",
       " {'word': '##IS',\n",
       "  'score': 0.9022265076637268,\n",
       "  'entity': 'I-MISC',\n",
       "  'index': 73},\n",
       " {'word': '##PR',\n",
       "  'score': 0.8369854092597961,\n",
       "  'entity': 'I-MISC',\n",
       "  'index': 74}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_es_classifier(texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La salida del reconocedor de entidades es una lista de diccionarios normal de Python. Si te fijas con atención, cada elemento de la lista es un token, y estos tokens son radicalmente diferentes a los que hemos visto hasta ahora. Hay tokens que coinciden con unidades que llamaríamos palabras (*premio*, *Nobel* o *química*), pero otros tokens son secuencias menores, algunos de ellos sin sentido gramatical. Esto suele ocurrir con nombres propios que no son habituales en español y con palabras de reciente creación (*Charpentier* se tokeniza `Char` `##pent`, `##ier` ; *CRISPR* se tokeniza como `CR`, `##IS`, `##PR`), pero también podemos encontrar esta tokenización en palabras perfectamente españolas como *sueca* (`sue`,`##ca`). \n",
    "\n",
    "[Este tipo de tokenización tiene un porqué](https://huggingface.co/transformers/tokenizer_summary.html), pero por el momento, es suficiente con que entiendas que cuando un token es la continuación de una unidad subpalabra, se especifica con dos almohadillas (`##`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Char es una mención a una persona con una probabilidad de 1.00\n",
      "##pent es una mención a una persona con una probabilidad de 0.62\n",
      "##ier es una mención a una persona con una probabilidad de 0.58\n",
      "Do es una mención a una persona con una probabilidad de 0.99\n",
      "##ud es una mención a una persona con una probabilidad de 0.54\n",
      "##na es una mención a una persona con una probabilidad de 0.94\n",
      "Emma es una mención a una persona con una probabilidad de 1.00\n",
      "##nu es una mención a una persona con una probabilidad de 0.99\n",
      "##elle es una mención a una persona con una probabilidad de 1.00\n",
      "Char es una mención a una persona con una probabilidad de 1.00\n",
      "##pent es una mención a una persona con una probabilidad de 1.00\n",
      "##ier es una mención a una persona con una probabilidad de 1.00\n",
      "[UNK] es una mención a una persona con una probabilidad de 1.00\n",
      "A es una mención a una persona con una probabilidad de 1.00\n",
      ". es una mención a una persona con una probabilidad de 1.00\n",
      "Do es una mención a una persona con una probabilidad de 1.00\n",
      "##ud es una mención a una persona con una probabilidad de 1.00\n",
      "##na es una mención a una persona con una probabilidad de 1.00\n",
      "Francis es una mención a una persona con una probabilidad de 1.00\n",
      "Mo es una mención a una persona con una probabilidad de 1.00\n",
      "##ji es una mención a una persona con una probabilidad de 1.00\n",
      "##ca es una mención a una persona con una probabilidad de 1.00\n"
     ]
    }
   ],
   "source": [
    "for token in ner_es_classifier(texto):\n",
    "    if token[\"entity\"].endswith(\"PER\"):\n",
    "        print(f\"\"\"{token[\"word\"]} es una mención a una persona con una probabilidad de {token[\"score\"]:.2f}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para probar el reconocedor de entidades en inglés, es suficiente con que busquemos un modelo adecuado e instanciemos un *pipeline* con él."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_en_classifier = pipeline(\"ner\", model=\"dslim/bert-base-NER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'Trump',\n",
       "  'score': 0.9974536895751953,\n",
       "  'entity': 'B-PER',\n",
       "  'index': 19},\n",
       " {'word': 'Chinese',\n",
       "  'score': 0.9997501969337463,\n",
       "  'entity': 'B-MISC',\n",
       "  'index': 37},\n",
       " {'word': 'United',\n",
       "  'score': 0.9997009634971619,\n",
       "  'entity': 'B-LOC',\n",
       "  'index': 57},\n",
       " {'word': 'States',\n",
       "  'score': 0.9994767308235168,\n",
       "  'entity': 'I-LOC',\n",
       "  'index': 58},\n",
       " {'word': 'China',\n",
       "  'score': 0.9998029470443726,\n",
       "  'entity': 'B-LOC',\n",
       "  'index': 60}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_en_classifier(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de opinión con transformers\n",
    "\n",
    "Tenemos a nuestra disposición modelos de clasificación de texto entrenados para reconocer la polaridad de textos en inglés. Podemos crear un clasificador de sentimiento con el modelo por defecto y probar qué tal funciona con algunas frases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# si no especificamos el modelo, utilizamos el definido por defecto para la tarea de sentiment analysis\n",
    "sentiment_classifier = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La frase \"I love ice-cream!\" es \n",
      "[{'label': 'POSITIVE', 'score': 0.9998226165771484}] \n",
      "\n",
      "La frase \"Don't ever go to this restaurant. The food was horrible :-(\" es \n",
      "[{'label': 'NEGATIVE', 'score': 0.9981479644775391}] \n",
      "\n",
      "La frase \"Evil Corp to announce job cuts.\" es \n",
      "[{'label': 'NEGATIVE', 'score': 0.9994521737098694}] \n",
      "\n",
      "La frase \"What a wonderful world!\" es \n",
      "[{'label': 'POSITIVE', 'score': 0.9998851418495178}] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ejemplo in oraciones:\n",
    "    print(f\"\"\"La frase \"{ejemplo}\" es \"\"\")\n",
    "    print(sentiment_classifier(ejemplo), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Búsqueda de respuestas con transformers\n",
    "\n",
    "Hasta ahora no habíamos podido probar tareas de PLN más complejas, pero transformers nos da acceso a modelos entrenados para tareas como la búsqueda de respuestas que tienen un rendimiento sorprendentemente bueno, al menos en inglés. Vamos a comprobar qué tal funcionan.\n",
    "\n",
    "Lo primero es cargar el extractor de respuestas con el modelo por defecto en inglés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = pipeline(\"question-answering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación definimos una serie de pares pregunta-contexto, con textos en lenguaje natural pegados directamente de artículos de Wikipedia.\n",
    "\n",
    "El modelo de búsqueda de respuestas es de tipo extractivo, no generativo. Esto implica que el modelo espera procesar e interpretar una pregunta y un contexto, susceptible de contener la respuesta. Intentará interpretar el tipo de pregunta y devolverá el segmento del contexto con mayor probabilidad de ser la respuesta. Ten en cuenta que el modelo es extractivo, por lo tanto es incapaz de reescribir la respuesta.\n",
    "\n",
    "Con estos ejemplos funciona perfectamente. Parece que hemos alcanzado la singularidad y que la humanidad está a merced de las máquinas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What city are the Lakers from?\n",
      "{'score': 0.2602875530719757, 'start': 4, 'end': 15, 'answer': 'Los Angeles'} \n",
      "\n",
      "LeBron James date of birth\n",
      "{'score': 0.9441075921058655, 'start': 50, 'end': 68, 'answer': 'December 30, 1984)'} \n",
      "\n",
      "Who won the NBA finals?\n",
      "{'score': 0.2531222105026245, 'start': 221, 'end': 239, 'answer': 'Los Angeles Lakers'} \n",
      "\n",
      "What was the score?\n",
      "{'score': 0.955236554145813, 'start': 293, 'end': 297, 'answer': '4–2,'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "preguntas_contextos = [\n",
    "    {\n",
    "        \"question\": \"What city are the Lakers from?\",\n",
    "        \"context\": \"The Los Angeles Lakers are an American professional basketball team based in Los Angeles.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"LeBron James date of birth\",\n",
    "        \"context\": \"LeBron Raymone James Sr. (/ləˈbrɒn/ lə-BRON; born December 30, 1984) is an American professional basketball player for the Los Angeles Lakers of the National Basketball Association (NBA).\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Who won the NBA finals?\",\n",
    "        \"context\": \"The 2020 NBA Finals was the championship series of the National Basketball Association (NBA)'s 2019–20 season and conclusion of the season's playoffs. In this best-of-seven playoff series, the Western Conference champion Los Angeles Lakers defeated the Eastern Conference champion Miami Heat, 4–2, winning their first NBA championship in ten years.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What was the score?\",\n",
    "        \"context\": \"The 2020 NBA Finals was the championship series of the National Basketball Association (NBA)'s 2019–20 season and conclusion of the season's playoffs. In this best-of-seven playoff series, the Western Conference champion Los Angeles Lakers defeated the Eastern Conference champion Miami Heat, 4–2, winning their first NBA championship in ten years.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for ejemplo in preguntas_contextos:\n",
    "    print(ejemplo[\"question\"])\n",
    "    print(qa(ejemplo), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, cuando el modelo recibe un contexto no directamente relacionado con la pregunta, empieza a dudar y le vemos las vergüenzas. Claramente no entiende lo que está haciendo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.3653542399406433, 'start': 67, 'end': 75, 'answer': 'American'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\n",
    "    {\n",
    "        \"question\": \"What are you from?\",\n",
    "        \"context\": \"The New York Times (NYT), sometimes also known as The Times, is an American newspaper based in New York City with worldwide influence and readership\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.12368953973054886, 'start': 0, 'end': 4, 'answer': 'Love'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\n",
    "    {\n",
    "        \"question\": \"What's the capital city of Spain?\",\n",
    "        \"context\": \"Love is in the air, in the whisper of the trees. Love is in the air, in the thunder of the sea.\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumen automático con transformers\n",
    "\n",
    "Otra de las tareas que combinan NLU y NLP que tenemos disponible en transformers con muy pocas líneas de código es el resumen automático. Si creamos un *pipeline* para resumir, podremos procesar documentos largos de entrada y seleccionar aquellas frases que mejor resuman el contenido semántico del documento original.\n",
    "\n",
    "Ten en cuenta que, en muchas ocasiones, a estos resúmenes les faltará la naturalidad, la coherencia y la cohesión típica de un resumen hecho a mano por seres humanos, pero el resultado sí que sintetizará el contenido de manera satisfactoria, lo que puede ser suficiente en muchos contextos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargado el modelo, veamos qué tal funciona con textos extraídos de Wikipedia y de la prensa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' The New York Times (NYT) is an American newspaper based in New York City . Founded in 1851, the paper has won 130 Pulitzer Prizes, more than any other newspaper . It is ranked 18th in the world by circulation and 3rd in the U.S.'}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documento_largo = \"\"\"The New York Times (NYT), sometimes also known as The Times,[6] is an American newspaper based in New York City with worldwide influence and readership.[7][8] Nicknamed \"the Gray Lady\",[9] the Times has long been regarded within the industry as a national \"newspaper of record\".[10] The paper's motto, \"All the News That's Fit to Print\", appears in the upper left-hand corner of the front page. Founded in 1851, the paper has won 130 Pulitzer Prizes, more than any other newspaper.[11][12] It is ranked 18th in the world by circulation and 3rd in the U.S.[13]\n",
    "\n",
    "The paper is owned by The New York Times Company, which is publicly traded. It has been owned by the Sulzberger family since 1896 through a dual-class share structure.[14] A. G. Sulzberger and his father, Arthur Ochs Sulzberger Jr.—the paper's publisher and the company's chairman, respectively—are the fourth and fifth generation of the family to head the paper.[15]\n",
    "\n",
    "Since the mid-1970s, The New York Times has greatly expanded its layout and organization, adding special weekly sections on various topics supplementing the regular news, editorials, sports, and features. Since 2008,[16] the Times has been organized into the following sections: News, Editorials/Opinions-Columns/Op-Ed, New York (metropolitan), Business, Sports, Arts, Science, Styles, Home, Travel, and other features.[17] On Sundays, the Times is supplemented by the Sunday Review (formerly the Week in Review),[18] The New York Times Book Review,[19] The New York Times Magazine,[20] and T: The New York Times Style Magazine.[21]\n",
    "\n",
    "The Times stayed with the broadsheet full-page set-up and an eight-column format for several years after most papers switched to six,[22] and was one of the last newspapers to adopt color photography, especially on the front page.[23]\n",
    "\"\"\"\n",
    "\n",
    "summarizer(documento_largo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Rafael Nadal equalled Roger Federer's record of 20 Grand Slam men's singles titles . Nadal defeated Novak Djokovic 6-0 6-2 7-5 to claim his 13th French Open title . Federer thanked Nadal and said their relationship \"means a lot\" Nadal: \"I have always had the utmost respect for my friend Rafa\"\n"
     ]
    }
   ],
   "source": [
    "documento_largo_2 = \"\"\"Roger Federer hailed his \"greatest rival\" after Rafael Nadal equalled his record of 20 Grand Slam men's singles titles in devastating fashion.\n",
    "\n",
    "Nadal, 34, comprehensively outplayed the other member of the sport's 'Big Three', Novak Djokovic 6-0 6-2 7-5 to claim his 13th French Open title.\n",
    "\n",
    "\"I have always had the utmost respect for my friend Rafa as a person and as a champion,\" the Swiss great tweeted.\n",
    "\n",
    "In response, Nadal thanked Federer and said their relationship \"means a lot\".\n",
    "\n",
    "The Spaniard continued: \"As everybody know we have a very, very good relationship and we respect each other a lot and at the same time I think he is happy when I am winning and I'm happy when he is doing things well.\n",
    "\n",
    "\"In some ways it means a lot, the positive relationship we have together because we have been going through a great rivalry for a very, very long time.\"\n",
    "\n",
    "Federer, who missed Roland Garros this year after knee surgery, added: \"I hope 20 is just another step on the continuing journey for both of us.\n",
    "\n",
    "\"As my greatest rival over many years, I believe we have pushed each other to become better players.\n",
    "\n",
    "\"Therefore, it is a true honour for me to congratulate him on his 20th Grand Slam victory. It is especially amazing that he has now won Roland Garros an incredible 13 times, which is one of the greatest achievements in sport.\n",
    "\"\"\"\n",
    "\n",
    "print(summarizer(documento_largo_2)[0][\"summary_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "En esta segunda nota técnica, hemos presentado tres de las librerías de Python más populares para realizar tareas de procesamiento del lenguaje natural: [spaCy](http://www.spacy.io/), [flair](https://github.com/flairNLP/flair) y [transformers](https://huggingface.co/transformers/).\n",
    "\n",
    "Hemos aprendido cómo cargar modelos pre-entrenados que están disponibles en todas ellas para realizar tareas básicas de NLU como son la tokenización, el análisis morfo-sintáctico y el reconocimiento de entidades y tareas no tan básicas como la búsqueda de respuestas y el resumen automático."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
