{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@import url('https://fonts.googleapis.com/css?family=Montserrat');\n",
       "\n",
       "h1, h2, h3 {\n",
       "    font-family: Montserrat;\n",
       "    font-weight: bold;\n",
       "    position: static;\n",
       "    color: #ffcf21;\n",
       "}\n",
       "\n",
       "p, li {\n",
       "    font-family: Montserrat;\n",
       "    size: 11px;\n",
       "    text-align: justify;\n",
       "    text-justify: inter-word;\n",
       "}\n",
       "\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# esta celda controla el estilo del cuaderno\n",
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librer铆as de PLN en Python\n",
    "\n",
    "## Introduccci贸n\n",
    "\n",
    "Como ocurre en otras 谩reas relacionadas con la Ciencia de Datos y el Aprendizaje Autom谩tico, Python es probablemente el lenguaje de programaci贸n que tiene disponibles m谩s herramientas para realizar tareas de Procesamiento del Lenguaje Natural. En esta nota t茅cnica vamos a hablar de tres de ellas: [spaCy](http://www.spacy.io/), [flair](https://github.com/flairNLP/flair) y [transformers](https://huggingface.co/transformers/). \n",
    "\n",
    "\n",
    "## spaCy\n",
    "\n",
    "[spaCy](http://www.spacy.io/), de la empresa [Explosion](https://explosion.ai/), es una librer铆a de procesamiento del lenguaje natural, de alto nivel, robusta, r谩pida, f谩cil de instalar y utilizar, e integrable con [otras librer铆as de *NLP* y de *deep learning*](https://spacy.io/universe). \n",
    "\n",
    "Tiene modelos entrenados en varios idiomas y permite realizar las [t铆picas tareas](https://spacy.io/usage/facts-figures) de segmentaci贸n por oraciones, tokenizanci贸n, an谩lisis morfol贸gico, extracci贸n de entidades y an谩lisis de opini贸n. Vamos a aprender a utilizarla.\n",
    "\n",
    "### Instalamos las dependencias\n",
    "\n",
    "Lo primero que vamos a hacer es instalar la librer铆a y [descargar un par de modelos](https://spacy.io/usage/models) que ya est谩n entrenados y que nos van a permiter realizar tareas de PLN en ingl茅s y espa帽ol.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "  <p>Atenci贸n: Si est谩s ejecutando este cuaderno en local, aseg煤rate de que est谩s usando un entorno virtual.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# instalamos spacy\n",
    "!pip install -U spacy\n",
    "\n",
    "# y descargamos un par de modelos pre-entrenados para ingl茅s y espa帽ol\n",
    "!python -m spacy download es_core_news_md\n",
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentaci贸n y tokenizaci贸n con spaCy\n",
    "\n",
    "Para poder utilizar spaCy, necesitamos importar la librer铆a y crear un objeto de tipo analizador con alguno de los modelos instalados. Comencemos cargando el modelo en espa帽ol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# creamos un analizador con el modelo entrenado en espa帽ol\n",
    "nlp_es = spacy.load(\"es_core_news_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para analizar cualquier texto en lenguaje natural, basta con crear un objeto de tipo documento pas谩ndole una cadena de texto analizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"\"\"Premio Nobel de Qu铆mica 2020 para Charpentier y Doudna por CRISPR. La Real Academia Sueca de Ciencias otorga el Nobel de Qu铆mica a Emmanuelle Charpentier y Jennifer A. Doudna por el desarrollo de esta herramienta de edici贸n gen茅tica. El espa帽ol Francis Mojica se queda sin reconocimiento a pesar de haber descubierto el sistema CRISPR en bacterias.\"\"\"\n",
    "\n",
    "# y procesamos el texto\n",
    "doc = nlp_es(texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ver谩s que el paso anterior no produce ninguna salida aparente. Pero ese objeto `doc` que acabamos de crear en realidad contiene mucha informaci贸n resultado de ejecutar varias tareas de comprensi贸n del lenguaje natural sobre el contenido de `texto`. En una sola l铆nea de c贸digo hemos segmentado el texto en oraciones, hemos tokenizado las oraciones, hemos realizado el an谩lisis morfo-sint谩ctico de las oraciones y hemos hecho reconocimiento de entidades.\n",
    "\n",
    "Veamos a continuaci贸n c贸mo podemos acceder a esa informaci贸n de manera program谩tica.\n",
    "\n",
    "Podemos iterar sobre las oraciones del documento a trav茅s de la propiedad `doc.sents`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premio Nobel de Qu铆mica 2020 para Charpentier y Doudna por CRISPR.\n",
      "\n",
      "La Real Academia Sueca de Ciencias otorga el Nobel de Qu铆mica a Emmanuelle Charpentier y Jennifer A. Doudna por el desarrollo de esta herramienta de edici贸n gen茅tica.\n",
      "\n",
      "El espa帽ol Francis Mojica se queda sin reconocimiento a pesar de haber descubierto el sistema CRISPR en bacterias.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for oracion in doc.sents:\n",
    "    print(f\"{oracion}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada oraci贸n est谩 a su vez segmentada en unidades indivisibles llamados *tokens*. En este caso de spaCy, los tokens coinciden con la idea intuitiva de lo que es una palabra o un signo de puntuaci贸n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La oraci贸n 1 tiene 12 tokens.\n",
      "La oraci贸n 2 tiene 28 tokens.\n",
      "La oraci贸n 3 tiene 19 tokens.\n"
     ]
    }
   ],
   "source": [
    "for n, oracion in enumerate(doc.sents):\n",
    "    print(f\"La oraci贸n {n+1} tiene {len(oracion)} tokens.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para verlo m谩s claro y poder reutilizar el c贸digo, vamos a crear una sencilla funci贸n para tokenizar texto usando spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['驴', 'Esto', 'es', 'solo', 'una', 'texto', 'de', 'ejemplo', '?', 'Mmm', '...', '隆', 'Pues', 'parece', 'que', 's铆', '', '!']\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "def tokenize(text: str, model: spacy.language.Language) -> List[str]:\n",
    "    \"\"\"Returns a tokenized version of a text using a spaCy model\"\"\"\n",
    "    return [t.text for t in model(text)]\n",
    "\n",
    "print(tokenize(\"驴Esto es solo una texto de ejemplo? Mmm... 隆Pues parece que s铆 !\", model=nlp_es))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y si probamos a tokenizar varias oraciones de ejemplo, ver谩s que efectivamente los tokens coinciden con la idea intuitiva que tenemos en espa帽ol de lo que es una palabra, un emoji o un signo de puntuaci贸n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Premio', 'Nobel', 'de', 'Qu铆mica', '2020', 'para', 'Charpentier', 'y', 'Doudna', 'por', 'CRISPR', '.'] \n",
      "\n",
      "['La', 'Real', 'Academia', 'Sueca', 'de', 'Ciencias', 'otorga', 'el', 'Nobel', 'de', 'Qu铆mica', 'a', 'Emmanuelle', 'Charpentier', 'y', 'Jennifer', 'A.', 'Doudna', 'por', 'el', 'desarrollo', 'de', 'esta', 'herramienta', 'de', 'edici贸n', 'gen茅tica', '.'] \n",
      "\n",
      "['El', 'espa帽ol', 'Francis', 'Mojica', 'se', 'queda', 'sin', 'reconocimiento', 'a', 'pesar', 'de', 'haber', 'descubierto', 'el', 'sistema', 'CRISPR', 'en', 'bacterias', '.'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for oracion in doc.sents:\n",
    "    print(tokenize(oracion.text, model=nlp_es), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M谩s adelante veremos c贸mo es esta tokenizaci贸n en ingl茅s.\n",
    "\n",
    "### An谩lisis morfo-sint谩ctico son spaCy\n",
    "\n",
    "El documento que hemos analizado contiene completa informaci贸n morfo-sint谩ctica de todos los tokens. 驴Qu茅 tipo de informaci贸n es esta? Veamos un ejemplo sobre una de las oraciones y [revisa la documentaci贸n del API de spaCy](https://spacy.io/api/token)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El token \"El\" ocupa la posici贸n 40, entre los 铆ndices 234 y 236.\n",
      "Tiene como forma can贸nica la forma \"El\".\n",
      "Es una palabra de tipo DET con los siguientes rasgos morfol贸gicos: DET__Definite=Def|Gender=Masc|Number=Sing|PronType=Art.\n",
      "Su funci贸n en la oraci贸n es det.\n",
      "\n",
      "El token \"espa帽ol\" ocupa la posici贸n 41, entre los 铆ndices 237 y 244.\n",
      "Tiene como forma can贸nica la forma \"espa帽ol\".\n",
      "Es una palabra de tipo NOUN con los siguientes rasgos morfol贸gicos: NOUN__Gender=Masc|Number=Sing.\n",
      "Su funci贸n en la oraci贸n es nsubj.\n",
      "\n",
      "El token \"Francis\" ocupa la posici贸n 42, entre los 铆ndices 245 y 252.\n",
      "Tiene como forma can贸nica la forma \"Francis\".\n",
      "Es una palabra de tipo PROPN con los siguientes rasgos morfol贸gicos: PROPN.\n",
      "Su funci贸n en la oraci贸n es appos.\n",
      "\n",
      "El token \"Mojica\" ocupa la posici贸n 43, entre los 铆ndices 253 y 259.\n",
      "Tiene como forma can贸nica la forma \"Mojica\".\n",
      "Es una palabra de tipo PROPN con los siguientes rasgos morfol贸gicos: PROPN.\n",
      "Su funci贸n en la oraci贸n es flat.\n",
      "\n",
      "El token \"se\" ocupa la posici贸n 44, entre los 铆ndices 260 y 262.\n",
      "Tiene como forma can贸nica la forma \"se\".\n",
      "Es una palabra de tipo PRON con los siguientes rasgos morfol贸gicos: PRON__Case=Acc,Dat|Person=3|PrepCase=Npr|PronType=Prs|Reflex=Yes.\n",
      "Su funci贸n en la oraci贸n es obj.\n",
      "\n",
      "El token \"queda\" ocupa la posici贸n 45, entre los 铆ndices 263 y 268.\n",
      "Tiene como forma can贸nica la forma \"quedo\".\n",
      "Es una palabra de tipo VERB con los siguientes rasgos morfol贸gicos: VERB__Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin.\n",
      "Su funci贸n en la oraci贸n es ROOT.\n",
      "\n",
      "El token \"sin\" ocupa la posici贸n 46, entre los 铆ndices 269 y 272.\n",
      "Tiene como forma can贸nica la forma \"sin\".\n",
      "Es una palabra de tipo ADP con los siguientes rasgos morfol贸gicos: ADP__AdpType=Prep.\n",
      "Su funci贸n en la oraci贸n es case.\n",
      "\n",
      "El token \"reconocimiento\" ocupa la posici贸n 47, entre los 铆ndices 273 y 287.\n",
      "Tiene como forma can贸nica la forma \"reconocimiento\".\n",
      "Es una palabra de tipo NOUN con los siguientes rasgos morfol贸gicos: NOUN__Gender=Masc|Number=Sing.\n",
      "Su funci贸n en la oraci贸n es obl.\n",
      "\n",
      "El token \"a\" ocupa la posici贸n 48, entre los 铆ndices 288 y 289.\n",
      "Tiene como forma can贸nica la forma \"a\".\n",
      "Es una palabra de tipo ADP con los siguientes rasgos morfol贸gicos: ADP__AdpType=Prep.\n",
      "Su funci贸n en la oraci贸n es mark.\n",
      "\n",
      "El token \"pesar\" ocupa la posici贸n 49, entre los 铆ndices 290 y 295.\n",
      "Tiene como forma can贸nica la forma \"pesar\".\n",
      "Es una palabra de tipo INTJ con los siguientes rasgos morfol贸gicos: NOUN.\n",
      "Su funci贸n en la oraci贸n es fixed.\n",
      "\n",
      "El token \"de\" ocupa la posici贸n 50, entre los 铆ndices 296 y 298.\n",
      "Tiene como forma can贸nica la forma \"de\".\n",
      "Es una palabra de tipo ADP con los siguientes rasgos morfol贸gicos: ADP__AdpType=Prep.\n",
      "Su funci贸n en la oraci贸n es fixed.\n",
      "\n",
      "El token \"haber\" ocupa la posici贸n 51, entre los 铆ndices 299 y 304.\n",
      "Tiene como forma can贸nica la forma \"haber\".\n",
      "Es una palabra de tipo VERB con los siguientes rasgos morfol贸gicos: AUX__VerbForm=Inf.\n",
      "Su funci贸n en la oraci贸n es aux.\n",
      "\n",
      "El token \"descubierto\" ocupa la posici贸n 52, entre los 铆ndices 305 y 316.\n",
      "Tiene como forma can贸nica la forma \"descubrir\".\n",
      "Es una palabra de tipo VERB con los siguientes rasgos morfol贸gicos: VERB__Gender=Masc|Number=Sing|Tense=Past|VerbForm=Part.\n",
      "Su funci贸n en la oraci贸n es advcl.\n",
      "\n",
      "El token \"el\" ocupa la posici贸n 53, entre los 铆ndices 317 y 319.\n",
      "Tiene como forma can贸nica la forma \"el\".\n",
      "Es una palabra de tipo DET con los siguientes rasgos morfol贸gicos: DET__Definite=Def|Gender=Masc|Number=Sing|PronType=Art.\n",
      "Su funci贸n en la oraci贸n es det.\n",
      "\n",
      "El token \"sistema\" ocupa la posici贸n 54, entre los 铆ndices 320 y 327.\n",
      "Tiene como forma can贸nica la forma \"sistema\".\n",
      "Es una palabra de tipo NOUN con los siguientes rasgos morfol贸gicos: NOUN__Gender=Masc|Number=Sing.\n",
      "Su funci贸n en la oraci贸n es obj.\n",
      "\n",
      "El token \"CRISPR\" ocupa la posici贸n 55, entre los 铆ndices 328 y 334.\n",
      "Tiene como forma can贸nica la forma \"CRISPR\".\n",
      "Es una palabra de tipo PROPN con los siguientes rasgos morfol贸gicos: PROPN.\n",
      "Su funci贸n en la oraci贸n es amod.\n",
      "\n",
      "El token \"en\" ocupa la posici贸n 56, entre los 铆ndices 335 y 337.\n",
      "Tiene como forma can贸nica la forma \"en\".\n",
      "Es una palabra de tipo ADP con los siguientes rasgos morfol贸gicos: ADP__AdpType=Prep.\n",
      "Su funci贸n en la oraci贸n es case.\n",
      "\n",
      "El token \"bacterias\" ocupa la posici贸n 57, entre los 铆ndices 338 y 347.\n",
      "Tiene como forma can贸nica la forma \"bacteria\".\n",
      "Es una palabra de tipo NOUN con los siguientes rasgos morfol贸gicos: NOUN__Gender=Fem|Number=Plur.\n",
      "Su funci贸n en la oraci贸n es obl.\n",
      "\n",
      "El token \".\" ocupa la posici贸n 58, entre los 铆ndices 347 y 348.\n",
      "Tiene como forma can贸nica la forma \".\".\n",
      "Es una palabra de tipo PUNCT con los siguientes rasgos morfol贸gicos: PUNCT__PunctType=Peri.\n",
      "Su funci贸n en la oraci贸n es punct.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tercera_oracion = list(doc.sents)[2]\n",
    "\n",
    "for token in tercera_oracion:\n",
    "    print(f\"\"\"El token \"{token}\" ocupa la posici贸n {token.i}, entre los 铆ndices {token.idx} y {token.idx+len(token.text)}.\"\"\")\n",
    "    print(f\"\"\"Tiene como forma can贸nica la forma \"{token.lemma_}\".\"\"\")\n",
    "    print(f\"\"\"Es una palabra de tipo {token.pos_} con los siguientes rasgos morfol贸gicos: {token.tag_}.\"\"\")\n",
    "    print(f\"\"\"Su funci贸n en la oraci贸n es {token.dep_}.\\n\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la celda anterior hemos impreso por pantalla toda la informaci贸n relevante para describir los tokens de una de las oraciones. Estamos imprimiendo la posici贸n y los *offsets* del token, el tipo de palabra o categor铆a gramatical a la que pertenece, su lema (la forma can贸nica bajo la que aparece en el diccionario), los rasgos morfol贸gicos asociados (dependiendo del tipo de palabra, imprimimos el g茅nero y el n煤mero, o la persona y el tiempo, etc.) y la funci贸n que desempe帽a en la oraci贸n. \n",
    "\n",
    "No pretendo que conozcas el significado de toda la informaci贸n que aparece, aunque algunas cosas s铆 es posible que te suenen de las clases de lengua. Por ejemplo, etiquetas como `DET`, `NOUN`, `VERB`, y `PROPN` se utilizan para describir respectivamente determinantes, nombres comunes, verbos y nombres propios. Los rasgos `Gender=Masc|Number=Sing|Tense=Past|VerbForm=Part` describen un token como forma verbal de tipo participio, g茅nero m谩sculino, n煤mero singular, tiempo pasado.\n",
    "\n",
    "S铆 es importante que sepas que estas etiquetas est谩n dise帽adas para describir la morfolog铆a y la sintaxis de muchas lenguas del mundo y que siguen las convenciones habituales en el 谩mbito de la ling眉铆stica y el PLN que se recogen bajo el proyecto [Universal Dependencies](https://universaldependencies.org/guidelines.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconocimiento de entidades con spaCy\n",
    "\n",
    "El texto que hemos analizado conten铆a varias entidades nombradas, esto es menciones a personas, organizaciones y lugares. Te en cuenta que algunas menciones pueden tener m谩s de un token. Veamos c贸mo podemos acceder a ellas a trav茅s de la propiedad `doc.ents`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El documento analizado contiene 10 entidades.\n",
      "\n",
      "  1. La menci贸n \"Premio Nobel de Qu铆mica 2020\" es de tipo MISC, y ocupa los tokens 0-5.\n",
      "  2. La menci贸n \"Charpentier\" es de tipo PER, y ocupa los tokens 6-7.\n",
      "  3. La menci贸n \"Doudna\" es de tipo PER, y ocupa los tokens 8-9.\n",
      "  4. La menci贸n \"CRISPR\" es de tipo ORG, y ocupa los tokens 10-11.\n",
      "  5. La menci贸n \"Real Academia Sueca de Ciencias\" es de tipo ORG, y ocupa los tokens 13-18.\n",
      "  6. La menci贸n \"Nobel de Qu铆mica\" es de tipo ORG, y ocupa los tokens 20-23.\n",
      "  7. La menci贸n \"Emmanuelle Charpentier\" es de tipo PER, y ocupa los tokens 24-26.\n",
      "  8. La menci贸n \"Jennifer A. Doudna\" es de tipo PER, y ocupa los tokens 27-30.\n",
      "  9. La menci贸n \"Francis Mojica\" es de tipo PER, y ocupa los tokens 42-44.\n",
      "  10. La menci贸n \"CRISPR\" es de tipo MISC, y ocupa los tokens 55-56.\n"
     ]
    }
   ],
   "source": [
    "print(f\"El documento analizado contiene {len(doc.ents)} entidades.\\n\")\n",
    "\n",
    "for n, entidad in enumerate(doc.ents):\n",
    "    print(f\"\"\"  {n+1}. La menci贸n \"{entidad}\" es de tipo {entidad.label_}, y ocupa los tokens {entidad.start}-{entidad.end}.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El [modelo en espa帽ol que estamos utilizando](https://spacy.io/models/es#es_core_news_md) es capaz de identificar solo cuatro tipos de entidades distintos: personas (`PER`), organizaciones (`ORG`), lugares (`LOC`) y entidades de otros tipos que se engloban dentro de la categor铆a `MISC`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La propia librer铆a contiene [varias maneras de visualizar el an谩lisis del documento](https://spacy.io/usage/visualizers), como se muestra en el reconocimiento de entidades de la celda siguiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"es\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Premio Nobel de Qu铆mica 2020\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " para \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Charpentier\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " y \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Doudna\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " por \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    CRISPR\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ". La \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Real Academia Sueca de Ciencias\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " otorga el \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Nobel de Qu铆mica\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " a \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Emmanuelle Charpentier\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " y \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Jennifer A. Doudna\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " por el desarrollo de esta herramienta de edici贸n gen茅tica. El espa帽ol \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Francis Mojica\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " se queda sin reconocimiento a pesar de haber descubierto el sistema \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    CRISPR\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " en bacterias.</div>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'ent' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.serve(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando spaCy con otras lenguas\n",
    "\n",
    "Hasta ahora hemos utilizado un modelo que ha sido entrenado con colleciones de datos en espa帽ol. No solo eso, si profundizas en la documentaci贸n de los modelos disponibles en spaCy, descubrir谩s que [este modelo se llama precisamente `es_core_news_md`](https://spacy.io/models/es#es_core_news_md) porque est谩 entrenado con datos en espa帽ol (`es`), sobre colecciones de noticias (`news`) y de los tres tama帽os disponibles este es el mediano (`md`).\n",
    "\n",
    "El tama帽o del modelo determina el rendimiento final. A *grosso modo*, cuanto m谩s grande sea, mejor calidad tendr谩, aunque ser谩 m谩s pesado y complejo de manejar. El origen de los datos tambi茅n hay que tenerlo en cuenta. Los textos provenientes de medios de comunicaci贸n de masas y noticias contienen ejemplos de lengua en su variante culta. Esto significa que funcionar谩n muy bien para analizar texto de las mismas caracter铆sticas, pero que probablemente funcionen mal si queremos procesar textos que usen la variante coloquial de la lengua o registros no est谩ndar, que es lo que ocurre en redes sociales o con la mensajer铆a instat谩nea. Mucho cuidado con usar modelos de PLN entrenados con noticias para tratar analizar mensajes de chat entre adolescentes. No van a a funcionar bien.\n",
    "\n",
    "En cualquier caso, en spaCy tenemos disponibles otros modelos entreandos para otras lenguas. Por ejemplo, el modelo que cargamos a continuaci贸n es de tama帽o mediano (`md`), est谩 entrenado con datos en ingl茅s (`en`), con documentos provenientes de la p谩ginas web, blogs, y comentarios de usuarios (`web`). *A priori*, este modelo deber铆a funcionar mejor para analizar lengua no culta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_en = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mismo c贸digo que hemos usado en las celdas anteriores sirve para procesar un texto en ingl茅s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"A trade war between the world's two largest economies officially began on Friday morning. The Trump administration followed through with its threat to impose tariffs on $34 billion worth of Chinese products, a significant escalation of a fight that could hurt companies and consumers in both the United States and China.\"\"\"\n",
    "\n",
    "# y procesamos el texto\n",
    "doc_en = nlp_en(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos segmentar en oraciones y tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A trade war between the world's two largest economies officially began on Friday morning.\n",
      "\n",
      "The Trump administration followed through with its threat to impose tariffs on $34 billion worth of Chinese products, a significant escalation of a fight that could hurt companies and consumers in both the United States and China.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for oracion in doc_en.sents:\n",
    "    print(f\"{oracion}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La oraci贸n 1 tiene 16 tokens.\n",
      "La oraci贸n 2 tiene 40 tokens.\n"
     ]
    }
   ],
   "source": [
    "for n, oracion in enumerate(doc_en.sents):\n",
    "    print(f\"La oraci贸n {n+1} tiene {len(oracion)} tokens.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a recuperar la funci贸n para tokenizar texto que hemos definido m谩s arriba. 驴C贸mo son los tokens que segmenta spaCy cuando la lengua es el ingl茅s?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'trade', 'war', 'between', 'the', 'world', \"'s\", 'two', 'largest', 'economies', 'officially', 'began', 'on', 'Friday', 'morning', '.'] \n",
      "\n",
      "['The', 'Trump', 'administration', 'followed', 'through', 'with', 'its', 'threat', 'to', 'impose', 'tariffs', 'on', '$', '34', 'billion', 'worth', 'of', 'Chinese', 'products', ',', 'a', 'significant', 'escalation', 'of', 'a', 'fight', 'that', 'could', 'hurt', 'companies', 'and', 'consumers', 'in', 'both', 'the', 'United', 'States', 'and', 'China', '.'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for oracion in doc_en.sents:\n",
    "    print(tokenize(oracion.text, model=nlp_en), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quiz谩 lo m谩s llamativo es que en ingl茅s se tokenizan algunas formas verbales que llevan contracciones, los genitivos saj贸n y algunos s铆mbolos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['You', \"'d\", 'better', 'go', 'with', 'those', '$', '1000', '!', 'You', 'are', \"n't\", 'as', 'smart', 'as', 'you', 'think', '.']\n"
     ]
    }
   ],
   "source": [
    "print(tokenize(\"You'd better go with those $1000! You aren't as smart as you think.\", model=nlp_en))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hemos visto antes, el objeto `doc_en` tambi茅n contiene el an谩lisis morfo-sint谩ctico del texto. Imprimamos el de la primera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El token \"A\" ocupa la posici贸n 0, entre los 铆ndices 0 y 1.\n",
      "Tiene como forma can贸nica la forma \"a\".\n",
      "Es una palabra de tipo DET con los siguientes rasgos morfol贸gicos: DT.\n",
      "Su funci贸n en la oraci贸n es det.\n",
      "\n",
      "El token \"trade\" ocupa la posici贸n 1, entre los 铆ndices 2 y 7.\n",
      "Tiene como forma can贸nica la forma \"trade\".\n",
      "Es una palabra de tipo NOUN con los siguientes rasgos morfol贸gicos: NN.\n",
      "Su funci贸n en la oraci贸n es compound.\n",
      "\n",
      "El token \"war\" ocupa la posici贸n 2, entre los 铆ndices 8 y 11.\n",
      "Tiene como forma can贸nica la forma \"war\".\n",
      "Es una palabra de tipo NOUN con los siguientes rasgos morfol贸gicos: NN.\n",
      "Su funci贸n en la oraci贸n es nsubj.\n",
      "\n",
      "El token \"between\" ocupa la posici贸n 3, entre los 铆ndices 12 y 19.\n",
      "Tiene como forma can贸nica la forma \"between\".\n",
      "Es una palabra de tipo ADP con los siguientes rasgos morfol贸gicos: IN.\n",
      "Su funci贸n en la oraci贸n es prep.\n",
      "\n",
      "El token \"the\" ocupa la posici贸n 4, entre los 铆ndices 20 y 23.\n",
      "Tiene como forma can贸nica la forma \"the\".\n",
      "Es una palabra de tipo DET con los siguientes rasgos morfol贸gicos: DT.\n",
      "Su funci贸n en la oraci贸n es det.\n",
      "\n",
      "El token \"world\" ocupa la posici贸n 5, entre los 铆ndices 24 y 29.\n",
      "Tiene como forma can贸nica la forma \"world\".\n",
      "Es una palabra de tipo NOUN con los siguientes rasgos morfol贸gicos: NN.\n",
      "Su funci贸n en la oraci贸n es poss.\n",
      "\n",
      "El token \"'s\" ocupa la posici贸n 6, entre los 铆ndices 29 y 31.\n",
      "Tiene como forma can贸nica la forma \"'s\".\n",
      "Es una palabra de tipo PART con los siguientes rasgos morfol贸gicos: POS.\n",
      "Su funci贸n en la oraci贸n es case.\n",
      "\n",
      "El token \"two\" ocupa la posici贸n 7, entre los 铆ndices 32 y 35.\n",
      "Tiene como forma can贸nica la forma \"two\".\n",
      "Es una palabra de tipo NUM con los siguientes rasgos morfol贸gicos: CD.\n",
      "Su funci贸n en la oraci贸n es nummod.\n",
      "\n",
      "El token \"largest\" ocupa la posici贸n 8, entre los 铆ndices 36 y 43.\n",
      "Tiene como forma can贸nica la forma \"large\".\n",
      "Es una palabra de tipo ADJ con los siguientes rasgos morfol贸gicos: JJS.\n",
      "Su funci贸n en la oraci贸n es amod.\n",
      "\n",
      "El token \"economies\" ocupa la posici贸n 9, entre los 铆ndices 44 y 53.\n",
      "Tiene como forma can贸nica la forma \"economy\".\n",
      "Es una palabra de tipo NOUN con los siguientes rasgos morfol贸gicos: NNS.\n",
      "Su funci贸n en la oraci贸n es pobj.\n",
      "\n",
      "El token \"officially\" ocupa la posici贸n 10, entre los 铆ndices 54 y 64.\n",
      "Tiene como forma can贸nica la forma \"officially\".\n",
      "Es una palabra de tipo ADV con los siguientes rasgos morfol贸gicos: RB.\n",
      "Su funci贸n en la oraci贸n es advmod.\n",
      "\n",
      "El token \"began\" ocupa la posici贸n 11, entre los 铆ndices 65 y 70.\n",
      "Tiene como forma can贸nica la forma \"begin\".\n",
      "Es una palabra de tipo VERB con los siguientes rasgos morfol贸gicos: VBD.\n",
      "Su funci贸n en la oraci贸n es ROOT.\n",
      "\n",
      "El token \"on\" ocupa la posici贸n 12, entre los 铆ndices 71 y 73.\n",
      "Tiene como forma can贸nica la forma \"on\".\n",
      "Es una palabra de tipo ADP con los siguientes rasgos morfol贸gicos: IN.\n",
      "Su funci贸n en la oraci贸n es prep.\n",
      "\n",
      "El token \"Friday\" ocupa la posici贸n 13, entre los 铆ndices 74 y 80.\n",
      "Tiene como forma can贸nica la forma \"Friday\".\n",
      "Es una palabra de tipo PROPN con los siguientes rasgos morfol贸gicos: NNP.\n",
      "Su funci贸n en la oraci贸n es compound.\n",
      "\n",
      "El token \"morning\" ocupa la posici贸n 14, entre los 铆ndices 81 y 88.\n",
      "Tiene como forma can贸nica la forma \"morning\".\n",
      "Es una palabra de tipo NOUN con los siguientes rasgos morfol贸gicos: NN.\n",
      "Su funci贸n en la oraci贸n es pobj.\n",
      "\n",
      "El token \".\" ocupa la posici贸n 15, entre los 铆ndices 88 y 89.\n",
      "Tiene como forma can贸nica la forma \".\".\n",
      "Es una palabra de tipo PUNCT con los siguientes rasgos morfol贸gicos: ..\n",
      "Su funci贸n en la oraci贸n es punct.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "primera_oracion = list(doc_en.sents)[0]\n",
    "\n",
    "for token in primera_oracion:\n",
    "    print(f\"\"\"El token \"{token}\" ocupa la posici贸n {token.i}, entre los 铆ndices {token.idx} y {token.idx+len(token.text)}.\"\"\")\n",
    "    print(f\"\"\"Tiene como forma can贸nica la forma \"{token.lemma_}\".\"\"\")\n",
    "    print(f\"\"\"Es una palabra de tipo {token.pos_} con los siguientes rasgos morfol贸gicos: {token.tag_}.\"\"\")\n",
    "    print(f\"\"\"Su funci贸n en la oraci贸n es {token.dep_}.\\n\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si te fijas en la salida de este an谩lisis y lo comparas con el del espa帽ol, es probable que te llamen la atenci贸n varias cosas.\n",
    "\n",
    "- El an谩lisis no contiene rasgos morfol贸gicos. Esto ocurre porque el ingl茅s tiene una variaci贸n morfol贸gica muy pobre (comparada con el espa帽ol y otras lenguas). Si lo piensas un poco, los nombres en ingl茅s no tienen marca de g茅nero, los adjetivos no distinguen entre singular y plural, y la conjugaci贸n de los verbos es muy sencilla.\n",
    "\n",
    "- El an谩lisis morfo-sint谩ctico en ingl茅s muestra otras etiquetas. Ahora los determinantes, los nombres, los nombres propios y los vebos se anotan como `DT`, `NN` o `NNS`, `NNP` y `VB*`. 驴Por qu茅 pasa esto? Precisamente, por las caracter铆sticas de la lengua inglesa, tiene sentido utilizar un esquema espec铆fico adaptado a su vocabulario. El modelo en ingl茅s que estamos usando ha sido entrenado de manera supervisada con datos que contienen otro tipo de anotaciones. Si tienes curiosidad en profundizar en este otro *tagset*, el conjunto de etiquetas que aqu铆 aparece es muy conocido en el mundo del PLN porque fue el primero, y se denomina [etiquetas del corpus de Brown](https://en.wikipedia.org/wiki/Brown_Corpus#Part-of-speech_tags_used).\n",
    "\n",
    "Por 煤ltimo, tambi茅n podemos extraer y visualizar las entidades nombradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El documento analizado contiene 7 entidades.\n",
      "\n",
      "  1. La menci贸n \"two\" es de tipo CARDINAL, y ocupa los tokens 7-8.\n",
      "  2. La menci贸n \"Friday morning\" es de tipo TIME, y ocupa los tokens 13-15.\n",
      "  3. La menci贸n \"Trump\" es de tipo ORG, y ocupa los tokens 17-18.\n",
      "  4. La menci贸n \"$34 billion\" es de tipo MONEY, y ocupa los tokens 28-31.\n",
      "  5. La menci贸n \"Chinese\" es de tipo NORP, y ocupa los tokens 33-34.\n",
      "  6. La menci贸n \"the United States\" es de tipo GPE, y ocupa los tokens 50-53.\n",
      "  7. La menci贸n \"China\" es de tipo GPE, y ocupa los tokens 54-55.\n"
     ]
    }
   ],
   "source": [
    "print(f\"El documento analizado contiene {len(doc_en.ents)} entidades.\\n\")\n",
    "\n",
    "for n, entidad in enumerate(doc_en.ents):\n",
    "    print(f\"\"\"  {n+1}. La menci贸n \"{entidad}\" es de tipo {entidad.label_}, y ocupa los tokens {entidad.start}-{entidad.end}.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">A trade war between the world's \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    two\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " largest economies officially began on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Friday morning\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
       "</mark>\n",
       ". The \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Trump\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " administration followed through with its threat to impose tariffs on \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $34 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       " worth of \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Chinese\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " products, a significant escalation of a fight that could hurt companies and consumers in both \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the United States\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    China\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ".</div>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'ent' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.serve(doc_en, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqu铆 tambi茅n hay algunas diferencias que habr谩s notado con respecto al modelo en espa帽ol. En este caso, el modelo utiliza otros identificadores diferentes para las entidades y es capaz de reconocer m谩s tipos de entidades diferentes. Y en general, funciona mejor que el del espa帽ol. Esto ocurre b谩sicamente porque [este modelo en ingl茅s](https://spacy.io/models/en#en_core_web_md), tal y como se describe en la documentaci贸n de spaCy, ha sido entrenado con un dataset m谩s grande llamado [OntoNotes](https://catalog.ldc.upenn.edu/LDC2013T19).\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "  <p>Como en otros 谩mbitos que utilizan aproximaciones basadas en aprendizaje autom谩tico y <i>deep learning</i>, el rendikiento de un sistema depende m谩s de los datos que del algoritmo que hay detr谩s. En este caso, los datasets disponibles para el ingl茅s son notablemente mayores y de mayor calidad que los disponibles en otras lenguas.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flair\n",
    "\n",
    "[flair](https://github.com/flairNLP/flair) es una librer铆a de PLN de software libre desarrollada inicialmente por la divisi贸n de ingenier铆a de Zalando y basada en PyTorch. Permite acceder a funcionalidades muy interesantes para procesar lenguaje natural, algunas de ellas con aproximaciones muy modernas:\n",
    "\n",
    "- segmentar el texto y [realizar operaciones b谩sicas con lenguaje natural](https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_1_BASICS.md)\n",
    "- etiquetar texto en lenguaje natural con modelos preentrenados con [informaci贸n morfo-sint谩ctica, de entidades nombradas](https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_2_TAGGING.md)\n",
    "- clasificar autom谩ticamente texto\n",
    "- entrenar tus propios modelos para [construir otros clasificadores](https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_7_TRAINING_A_MODEL.md)\n",
    "- [representar las palabras como *embeddings*](https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_3_WORD_EMBEDDING.md) de distintos tipos\n",
    "\n",
    "Veamos c贸mo podemos acceder a algunas de sus funcionalidades, pero lo primero es asegurarnos de que tenemos la librer铆a instalada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instalamos flair\n",
    "!pip install -U flair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An谩lisis morfol贸gico con flair\n",
    "\n",
    "El API de flair es diferente al que hemos visto en spaCy. En lugar de importar un 煤nico modelo pre-entrenado capaz de maneajar todos los aspectos de una lengua, con flair tendremos que instanciar determinadas clases para representar las oraciones y el modelo que queremos utilizar, en funci贸n del tipo de tarea de PLN que queramos resolver. \n",
    "\n",
    "Por ejemplo, para analizar sint谩cticamente un texto con flair, necesitamos es importar dos cosas: \n",
    "\n",
    "1. una  la clase `Sentence`, que nos permite representar una secuencia de texto en lenguaje natural con sentido completo, \n",
    "2. como la tarea que queremos resolver implica procesar y etiquetar secuencias ordenadas de tokens, necesitamos importar un `SequenceTagger` y construirlo con un modelo espec铆fico capaz de manejar informaci贸n morfol贸gica. \n",
    "\n",
    "[Hay varios modelos disponibles](https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_2_TAGGING.md#list-of-pre-trained-sequence-tagger-models), pero en este ejemplo vamos a utilizar uno pre-entrenado para reconocer las categor铆as gramaticales en varios idiomas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-01 18:53:21,342 loading file /home/victor/.flair/models/pos-multi-fast.pt\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "# cargamos el analizador con un modelo multi-idioma en su versi贸n fast, que funciona en CPU\n",
    "# la primera vez que intentas cargar un modelo tendr谩s que descargalo \n",
    "tagger = SequenceTagger.load(\"pos-multi-fast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "  <p>Si tienes acceso a GPU, a trav茅s de <a href=\"https://colab.research.google.com/\" target=\"_blank\">Google Colab</a>, por ejemplo, no dudes en utilizar la versi贸n completa y cargar el modelo llamado<code>pos-multi</code>.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facebook <PROPN> naci贸 <VERB> hace <VERB> d茅cada <NOUN> y <CCONJ> media <NOUN> tras <ADP> una <DET> noche <NOUN> de <ADP> copas <NOUN> de <ADP> Mark <PROPN> Zuckerberg <PROPN> . <PUNCT> \n",
      "\n",
      "Grand <ADJ> d茅bat <NOUN> national <ADJ> : <PUNCT> suivez <VERB> Emmanuel <PROPN> Macron <PROPN> en <ADP> direct <NOUN> de <ADP> Bordeaux <PROPN> . <PUNCT> \n",
      "\n",
      "Hier <ADV> an <ADP> der <DET> Zufahrt <NOUN> zur <ADP> Startrampe <NOUN> 39A <PROPN> , <PUNCT> wo <ADV> vor <ADP> 50 <NUM> Jahren <NOUN> die <DET> gigantischen <ADJ> Saturn-Raketen <NOUN> der <DET> Apollo-Mondmissionen <NOUN> im <ADJ> Schneckentempo <NOUN> vorbeigefahren <VERB> sind <AUX> , <PUNCT> prangen <VERB> nun <ADV> die <DET> blauen <ADJ> Lettern <NOUN> des <DET> Raumfahrtunternehmens <NOUN> von <ADP> Elon <PROPN> Musk <PROPN> an <ADP> einem <DET> Hangar <NOUN> . <PUNCT> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "oracion_es = Sentence(\"Facebook naci贸 hace d茅cada y media tras una noche de copas de Mark Zuckerberg.\")\n",
    "tagger.predict(oracion_es)\n",
    "# imprimimos el an谩lisis\n",
    "print(oracion_es.to_tagged_string(), \"\\n\")\n",
    "\n",
    "oracion_fr = Sentence(\"Grand d茅bat national: suivez Emmanuel Macron en direct de Bordeaux.\")\n",
    "tagger.predict(oracion_fr)\n",
    "# imprimimos el an谩lisis\n",
    "print(oracion_fr.to_tagged_string(), \"\\n\")\n",
    "\n",
    "oracion_de = Sentence(\"Hier an der Zufahrt zur Startrampe 39A, wo vor 50 Jahren die gigantischen Saturn-Raketen der Apollo-Mondmissionen im Schneckentempo vorbeigefahren sind, prangen nun die blauen Lettern des Raumfahrtunternehmens von Elon Musk an einem Hangar.\")\n",
    "tagger.predict(oracion_de)\n",
    "# imprimimos el an谩lisis\n",
    "print(oracion_de.to_tagged_string(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La salida de este etiquetador morfol贸gico es bastante sencilla, solo imprime el nombre de la categor铆a gramatical, pero este modelo es capaz de reconocer clases de palabras en varias lenguas. Si te fijas, las etiquetas son las mismas que las utilizadas en [Universal Dependencies](https://universaldependencies.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Reconocimiento de entidades con flair\n",
    "\n",
    "El reconocimiento de entidades tambi茅n es una tarea que implica procesar un texto como una secuencia ordenada de tokens. En este caso, necesitamos instanciar otro `SequenceTagger` con el modelo espec铆fico para reconocer entidades en ingl茅s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-01 18:53:23,302 loading file /home/victor/.flair/models/en-ner-fast-conll03-v0.4.pt\n"
     ]
    }
   ],
   "source": [
    "# cargamos el modelo entrenado para reconocer de entidades\n",
    "# recuerda, NER -> named entities recognition\n",
    "tagger = SequenceTagger.load(\"ner-fast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Behind closed doors , freshman Rep <S-MISC> . Alexandria <B-PER> Ocasio <I-PER> Cortez <E-PER> threatened the Senate <S-ORG> of the United <B-LOC> States <E-LOC> to put those voting with Republicans <S-MISC> \" on a list \" for a primary challenge in the 2020 election .\n"
     ]
    }
   ],
   "source": [
    "# analizamos una oraci贸n\n",
    "oracion = Sentence(\"\"\"Behind closed doors, freshman Rep. Alexandria Ocasio Cortez threatened the Senate of the United States to put those voting with Republicans \"on a list\" for a primary challenge in the 2020 election.\"\"\")\n",
    "tagger.predict(oracion)\n",
    "# imprimimos el an谩lisis\n",
    "print(oracion.to_tagged_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La prestas atenci贸n a la salida impresa de este an谩lisis, ver谩s que contiene los tokens de la oraci贸n y solo aquellas menciones identificadas como entidades nombradas imprimir谩n informaci贸n adicional. Pero, 驴c贸mo se codifica e interpreta esta salida?\n",
    "\n",
    "El esquema de anotaci贸n que utiliza flair en este ejemplo es bastante habitual en tareas de reconocimiento de entidades y se denomina [esquema IOB (Inside-Outside-Beginning)](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)). \n",
    "\n",
    "Como ya sabes, un reconocedor de entidades generalista normalmente identificar谩 varios tipos de entidades diferentes: personas (`PER`), organizaciones (`ORG`), lugares (`LOC`) y otras entidades (`MISC`). Y como hemos visto antes, las menciones de las entidades nombradas pueden expandirse a lo largo de m谩s de un token. Pues bien, este esquema de anotaci贸n especifica con prefijos si el token en cuesti贸n es el primer elemento de la menci贸n (*beginning*: `B-`), si es un token dentro de la menci贸n (*inside*: `I-`), si es el 煤ltimo elemento de la menci贸n (*end*: `E-`), o si la entidad tiene un solo token (*single*: `S-`). De este modo, `Alexandria <B-PER> Ocasio <I-PER> Cortez <E-PER>` permite describir una entidad de tipo persona con tres tokens, `United <B-LOC> States <E-LOC>` es una entidad de tipo lugar con dos tokens, y `Republicans <S-MISC>` es una entidad de tipo indeterminado formada por un solo token.\n",
    "\n",
    "De manera program谩tica, puedes acceder a la informaci贸n completa de las entidades como se muestra en el siguiente ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La entidad \"Rep\" ocupa los tokens [6] y los offsets 30 y 33.\n",
      "Pertenece a la categoria MISC con una probabilidad de 0.9307801723480225.\n",
      "\n",
      "La entidad \"Alexandria Ocasio Cortez\" ocupa los tokens [8, 9, 10] y los offsets 35 y 59.\n",
      "Pertenece a la categoria PER con una probabilidad de 0.9782136678695679.\n",
      "\n",
      "La entidad \"Senate\" ocupa los tokens [13] y los offsets 75 y 81.\n",
      "Pertenece a la categoria ORG con una probabilidad de 0.9942795038223267.\n",
      "\n",
      "La entidad \"United States\" ocupa los tokens [16, 17] y los offsets 89 y 102.\n",
      "Pertenece a la categoria LOC con una probabilidad de 0.9732602536678314.\n",
      "\n",
      "La entidad \"Republicans\" ocupa los tokens [23] y los offsets 128 y 139.\n",
      "Pertenece a la categoria MISC con una probabilidad de 0.9998949766159058.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# iteramos por la entidades\n",
    "for entidad in oracion.get_spans(\"ner\"):\n",
    "    print(f\"\"\"La entidad \"{entidad.text}\" ocupa los tokens {[t.idx for t in entidad.tokens]} y los offsets {entidad.start_pos} y {entidad.end_pos}.\"\"\")\n",
    "    print(f\"\"\"Pertenece a la categoria {entidad.tag} con una probabilidad de {entidad.score}.\\n\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Behind closed doors, freshman Rep. Alexandria Ocasio Cortez threatened the Senate of the United States to put those voting with Republicans \"on a list\" for a primary challenge in the 2020 election.', 'labels': [], 'entities': [{'text': 'Rep', 'start_pos': 30, 'end_pos': 33, 'labels': [MISC (0.9308)]}, {'text': 'Alexandria Ocasio Cortez', 'start_pos': 35, 'end_pos': 59, 'labels': [PER (0.9782)]}, {'text': 'Senate', 'start_pos': 75, 'end_pos': 81, 'labels': [ORG (0.9943)]}, {'text': 'United States', 'start_pos': 89, 'end_pos': 102, 'labels': [LOC (0.9733)]}, {'text': 'Republicans', 'start_pos': 128, 'end_pos': 139, 'labels': [MISC (0.9999)]}]}\n"
     ]
    }
   ],
   "source": [
    "# o imprimimos la estructura de datos con el an谩lisis completo\n",
    "print(oracion.to_dict(tag_type=\"ner\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## An谩lisis de opini贸n con flair\n",
    "\n",
    "Otra interesante caracter铆stica de flair es que nos da acceso a modelos entrenados con informaci贸n sobre an谩lisis de opini贸n, que permiten detectar opiniones positivas y negativas.\n",
    "\n",
    "En este caso, la tarea de an谩lisis de opini贸n es un problema de claficaci贸n de texto, no de etiquetado por secuencia. Necesitaremos instanciar un objeto diferente: un `TextClassifier`, como se muestra en el siguiente ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-01 18:53:26,103 loading file /home/victor/.flair/models/sentiment-en-mix-distillbert_3.1.pt\n"
     ]
    }
   ],
   "source": [
    "from flair.models import TextClassifier\n",
    "\n",
    "classifier = TextClassifier.load(\"en-sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La oraci贸n \"I love ice-cream!\" \n",
      "contiene una opini贸n de tipo POSITIVE con una probabilidad de 1.00\n",
      "\n",
      "La oraci贸n \"Don't ever go to this restaurant. The food was horrible :-(\" \n",
      "contiene una opini贸n de tipo NEGATIVE con una probabilidad de 1.00\n",
      "\n",
      "La oraci贸n \"Evil Corp to announce job cuts.\" \n",
      "contiene una opini贸n de tipo NEGATIVE con una probabilidad de 1.00\n",
      "\n",
      "La oraci贸n \"What a wonderful world!\" \n",
      "contiene una opini贸n de tipo POSITIVE con una probabilidad de 1.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# definimos unas cuantas oraciones en ingl茅s\n",
    "oraciones = [\"I love ice-cream!\", \"Don't ever go to this restaurant. The food was horrible :-(\", \"Evil Corp to announce job cuts.\", \"What a wonderful world!\"]\n",
    "\n",
    "for oracion in oraciones:\n",
    "    s = Sentence(oracion)\n",
    "    classifier.predict(s)\n",
    "    polaridad, prob = s.labels[0].value, s.labels[0].score\n",
    "\n",
    "    print(f\"\"\"La oraci贸n \"{s.to_plain_string()}\" \"\"\")\n",
    "    print(f\"contiene una opini贸n de tipo {polaridad} con una probabilidad de {prob:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transformers\n",
    "\n",
    "[transformers](https://github.com/huggingface/transformers), liderada por la empresa [HuggingFace](https://huggingface.co/), se ha convertido en los 煤ltimos a帽os en una las librer铆as para tareas de NLU y NLG m谩s importantes. En un primer momento surgi贸 como un punto intermedio que permit铆a integrar en c贸digo de PyTorch modelos entrenados originalmente en TensorFlow. Actualmente, da acceso a [multitud de modelos pre-entrenados con un mismo API](https://huggingface.co/models) y est谩 en continua evoluci贸n, dado que cuenta con una comunidad de usuarios muy activa. \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "  <p>Si tienes curiosidad en profundizar, el nombre de esta librer铆a hace referencia a <a href=\"https://jalammar.github.io/illustrated-transformer\" target=\"_blank\">Transformer</a>, una popular arquitectura de <em>deep learning</em> que utiliza <a href=\"https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/\" target=\"_blank\">un mecanismo denominado <strong>atenci贸n</strong></a>, y que ha revolucionado el mundo del procesamiento del lenguaje natural.</p>\n",
    "</div>\n",
    "\n",
    "La [documentaci贸n de transformers es muy completa](https://huggingface.co/transformers/) y el alcance de la herramienta es muy amplio. Para el objetivo de nuestra asignatura, nos contentaremos con entender c贸mo podemos utilizar los modelos con uno de los interfaces de m谩s alto nivel: [los *pipelines*](https://huggingface.co/transformers/main_classes/pipelines.html). 隆Vamos all谩!\n",
    "\n",
    "Lo primero es instalar la librer铆a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instalamos flair\n",
    "!pip install -U transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "El objeto `pipeline` es una abstracci贸n que nos permite especifcar la tarea de PLN y cargar cualquier modelo pre-entrenado que est茅 disponible en nuestra m谩quina local o en [el registro de modelos p煤blicos de huggingFace](https://huggingface.co/models).\n",
    "\n",
    "Podemos crear un *pipeline* de varias maneras pero la forma m谩s sencilla es especificando el tipo de tarea y el modelo que queremos utilizar.\n",
    "\n",
    "### Reconocimiento de entidades con transformers\n",
    "\n",
    "Para realizar reconocimiento de entidades en espa帽ol, necesitamos encontrar un modelo adecuado para la tarea y el idioma. Si buscamos [modelos pre-entrenados para NER en espa帽ol](https://huggingface.co/models?filter=es&search=ner) encontraremos varios de ellos. Muy probablemente estos nombres no te dir谩n nada, pero no abrumes, te aseguro que siguen una nomenclatura bastante habitual en el mundillo. \n",
    "\n",
    "Por ejemplo, el modelo llamado [`mrm8488/bert-spanish-cased-finetuned-ner`](https://huggingface.co/mrm8488/bert-spanish-cased-finetuned-ner) lo ha entrenado un famoso miembro de la comunidad de HuggingFace llamado [`@mrm8488`](https://twitter.com/mrm8488), ajustando para reconocimiento de entidades (haciendo *fine tune* para NER en espa帽ol) un modelo BERT que distingue may煤sculas (*cased*). En cualquier caso, siempre puedes [acceder a una peque帽a ficha con informaci贸n extra, m茅tricas de evaluaci贸n y ejemplos de uso](https://huggingface.co/mrm8488/bert-spanish-cased-finetuned-ner).\n",
    "\n",
    "Vamos a ver qu茅 tal funciona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner_es_classifier = pipeline(\"ner\", model=\"mrm8488/bert-spanish-cased-finetuned-ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'word': 'Premio',\n",
       "  'score': 0.9974514245986938,\n",
       "  'entity': 'B-MISC',\n",
       "  'index': 1},\n",
       " {'word': 'Nobel',\n",
       "  'score': 0.9970600008964539,\n",
       "  'entity': 'I-MISC',\n",
       "  'index': 2},\n",
       " {'word': 'de', 'score': 0.9981623888015747, 'entity': 'I-MISC', 'index': 3},\n",
       " {'word': 'Qu铆mica',\n",
       "  'score': 0.9982280731201172,\n",
       "  'entity': 'I-MISC',\n",
       "  'index': 4},\n",
       " {'word': '2020', 'score': 0.922611653804779, 'entity': 'I-MISC', 'index': 5},\n",
       " {'word': 'Char', 'score': 0.9955931305885315, 'entity': 'B-PER', 'index': 7},\n",
       " {'word': '##pent',\n",
       "  'score': 0.6227113604545593,\n",
       "  'entity': 'B-PER',\n",
       "  'index': 8},\n",
       " {'word': '##ier', 'score': 0.5794926881790161, 'entity': 'B-PER', 'index': 9},\n",
       " {'word': 'Do', 'score': 0.9936509132385254, 'entity': 'B-PER', 'index': 11},\n",
       " {'word': '##ud', 'score': 0.5442298054695129, 'entity': 'I-PER', 'index': 12},\n",
       " {'word': '##na', 'score': 0.938393771648407, 'entity': 'I-PER', 'index': 13},\n",
       " {'word': 'CR', 'score': 0.9774543046951294, 'entity': 'B-MISC', 'index': 15},\n",
       " {'word': '##IS',\n",
       "  'score': 0.5223162174224854,\n",
       "  'entity': 'I-MISC',\n",
       "  'index': 16},\n",
       " {'word': 'La', 'score': 0.8818917870521545, 'entity': 'B-ORG', 'index': 19},\n",
       " {'word': 'Real', 'score': 0.5371993780136108, 'entity': 'B-ORG', 'index': 20},\n",
       " {'word': 'Academia',\n",
       "  'score': 0.9987961053848267,\n",
       "  'entity': 'I-ORG',\n",
       "  'index': 21},\n",
       " {'word': 'Sue', 'score': 0.999445915222168, 'entity': 'I-ORG', 'index': 22},\n",
       " {'word': '##ca', 'score': 0.9994853138923645, 'entity': 'I-ORG', 'index': 23},\n",
       " {'word': 'de', 'score': 0.9995753169059753, 'entity': 'I-ORG', 'index': 24},\n",
       " {'word': 'Ciencias',\n",
       "  'score': 0.9994133114814758,\n",
       "  'entity': 'I-ORG',\n",
       "  'index': 25},\n",
       " {'word': 'Nobel',\n",
       "  'score': 0.9944096207618713,\n",
       "  'entity': 'B-MISC',\n",
       "  'index': 28},\n",
       " {'word': 'de', 'score': 0.9756442904472351, 'entity': 'I-MISC', 'index': 29},\n",
       " {'word': 'Qu铆mica',\n",
       "  'score': 0.986515998840332,\n",
       "  'entity': 'I-MISC',\n",
       "  'index': 30},\n",
       " {'word': 'Emma', 'score': 0.9997843503952026, 'entity': 'B-PER', 'index': 32},\n",
       " {'word': '##nu', 'score': 0.9926055073738098, 'entity': 'I-PER', 'index': 33},\n",
       " {'word': '##elle',\n",
       "  'score': 0.997874915599823,\n",
       "  'entity': 'I-PER',\n",
       "  'index': 34},\n",
       " {'word': 'Char', 'score': 0.9996539354324341, 'entity': 'I-PER', 'index': 35},\n",
       " {'word': '##pent',\n",
       "  'score': 0.9994781613349915,\n",
       "  'entity': 'I-PER',\n",
       "  'index': 36},\n",
       " {'word': '##ier',\n",
       "  'score': 0.9987934231758118,\n",
       "  'entity': 'I-PER',\n",
       "  'index': 37},\n",
       " {'word': '[UNK]',\n",
       "  'score': 0.9997192025184631,\n",
       "  'entity': 'B-PER',\n",
       "  'index': 39},\n",
       " {'word': 'A', 'score': 0.9997491836547852, 'entity': 'I-PER', 'index': 40},\n",
       " {'word': '.', 'score': 0.9985464215278625, 'entity': 'I-PER', 'index': 41},\n",
       " {'word': 'Do', 'score': 0.9995366334915161, 'entity': 'I-PER', 'index': 42},\n",
       " {'word': '##ud', 'score': 0.9993067979812622, 'entity': 'I-PER', 'index': 43},\n",
       " {'word': '##na', 'score': 0.9977015852928162, 'entity': 'I-PER', 'index': 44},\n",
       " {'word': 'Francis',\n",
       "  'score': 0.9998371601104736,\n",
       "  'entity': 'B-PER',\n",
       "  'index': 57},\n",
       " {'word': 'Mo', 'score': 0.999780535697937, 'entity': 'I-PER', 'index': 58},\n",
       " {'word': '##ji', 'score': 0.9997037053108215, 'entity': 'I-PER', 'index': 59},\n",
       " {'word': '##ca', 'score': 0.9996520280838013, 'entity': 'I-PER', 'index': 60},\n",
       " {'word': 'CR', 'score': 0.994926393032074, 'entity': 'B-MISC', 'index': 72},\n",
       " {'word': '##IS',\n",
       "  'score': 0.9022265076637268,\n",
       "  'entity': 'I-MISC',\n",
       "  'index': 73},\n",
       " {'word': '##PR',\n",
       "  'score': 0.8369854092597961,\n",
       "  'entity': 'I-MISC',\n",
       "  'index': 74}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_es_classifier(texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La salida del reconocedor de entidades es una lista de diccionarios normal de Python. Si te fijas con atenci贸n, cada elemento de la lista es un token, y estos tokens son radicalmente diferentes a los que hemos visto hasta ahora. Hay tokens que coinciden con unidades que llamar铆amos palabras (*premio*, *Nobel* o *qu铆mica*), pero otros tokens son secuencias menores, algunos de ellos sin sentido gramatical. Esto suele ocurrir con nombres propios que no son habituales en espa帽ol y con palabras de reciente creaci贸n (*Charpentier* se tokeniza `Char` `##pent`, `##ier` ; *CRISPR* se tokeniza como `CR`, `##IS`, `##PR`), pero tambi茅n podemos encontrar esta tokenizaci贸n en palabras perfectamente espa帽olas como *sueca* (`sue`,`##ca`). \n",
    "\n",
    "[Este tipo de tokenizaci贸n tiene un porqu茅](https://huggingface.co/transformers/tokenizer_summary.html), pero por el momento, es suficiente con que entiendas que cuando un token es la continuaci贸n de una unidad subpalabra, se especifica con dos almohadillas (`##`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Char es una menci贸n a una persona con una probabilidad de 1.00\n",
      "##pent es una menci贸n a una persona con una probabilidad de 0.62\n",
      "##ier es una menci贸n a una persona con una probabilidad de 0.58\n",
      "Do es una menci贸n a una persona con una probabilidad de 0.99\n",
      "##ud es una menci贸n a una persona con una probabilidad de 0.54\n",
      "##na es una menci贸n a una persona con una probabilidad de 0.94\n",
      "Emma es una menci贸n a una persona con una probabilidad de 1.00\n",
      "##nu es una menci贸n a una persona con una probabilidad de 0.99\n",
      "##elle es una menci贸n a una persona con una probabilidad de 1.00\n",
      "Char es una menci贸n a una persona con una probabilidad de 1.00\n",
      "##pent es una menci贸n a una persona con una probabilidad de 1.00\n",
      "##ier es una menci贸n a una persona con una probabilidad de 1.00\n",
      "[UNK] es una menci贸n a una persona con una probabilidad de 1.00\n",
      "A es una menci贸n a una persona con una probabilidad de 1.00\n",
      ". es una menci贸n a una persona con una probabilidad de 1.00\n",
      "Do es una menci贸n a una persona con una probabilidad de 1.00\n",
      "##ud es una menci贸n a una persona con una probabilidad de 1.00\n",
      "##na es una menci贸n a una persona con una probabilidad de 1.00\n",
      "Francis es una menci贸n a una persona con una probabilidad de 1.00\n",
      "Mo es una menci贸n a una persona con una probabilidad de 1.00\n",
      "##ji es una menci贸n a una persona con una probabilidad de 1.00\n",
      "##ca es una menci贸n a una persona con una probabilidad de 1.00\n"
     ]
    }
   ],
   "source": [
    "for token in ner_es_classifier(texto):\n",
    "    if token[\"entity\"].endswith(\"PER\"):\n",
    "        print(f\"\"\"{token[\"word\"]} es una menci贸n a una persona con una probabilidad de {token[\"score\"]:.2f}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para probar el reconocedor de entidades en ingl茅s, es suficiente con que busquemos un modelo adecuado e instanciemos un *pipeline* con 茅l."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_en_classifier = pipeline(\"ner\", model=\"dslim/bert-base-NER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'Trump',\n",
       "  'score': 0.9974536895751953,\n",
       "  'entity': 'B-PER',\n",
       "  'index': 19},\n",
       " {'word': 'Chinese',\n",
       "  'score': 0.9997501969337463,\n",
       "  'entity': 'B-MISC',\n",
       "  'index': 37},\n",
       " {'word': 'United',\n",
       "  'score': 0.9997009634971619,\n",
       "  'entity': 'B-LOC',\n",
       "  'index': 57},\n",
       " {'word': 'States',\n",
       "  'score': 0.9994767308235168,\n",
       "  'entity': 'I-LOC',\n",
       "  'index': 58},\n",
       " {'word': 'China',\n",
       "  'score': 0.9998029470443726,\n",
       "  'entity': 'B-LOC',\n",
       "  'index': 60}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_en_classifier(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An谩lisis de opini贸n con transformers\n",
    "\n",
    "Tenemos a nuestra disposici贸n modelos de clasificaci贸n de texto entrenados para reconocer la polaridad de textos en ingl茅s. Podemos crear un clasificador de sentimiento con el modelo por defecto y probar qu茅 tal funciona con algunas frases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# si no especificamos el modelo, utilizamos el definido por defecto para la tarea de sentiment analysis\n",
    "sentiment_classifier = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La frase \"I love ice-cream!\" es \n",
      "[{'label': 'POSITIVE', 'score': 0.9998226165771484}] \n",
      "\n",
      "La frase \"Don't ever go to this restaurant. The food was horrible :-(\" es \n",
      "[{'label': 'NEGATIVE', 'score': 0.9981479644775391}] \n",
      "\n",
      "La frase \"Evil Corp to announce job cuts.\" es \n",
      "[{'label': 'NEGATIVE', 'score': 0.9994521737098694}] \n",
      "\n",
      "La frase \"What a wonderful world!\" es \n",
      "[{'label': 'POSITIVE', 'score': 0.9998851418495178}] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ejemplo in oraciones:\n",
    "    print(f\"\"\"La frase \"{ejemplo}\" es \"\"\")\n",
    "    print(sentiment_classifier(ejemplo), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B煤squeda de respuestas con transformers\n",
    "\n",
    "Hasta ahora no hab铆amos podido probar tareas de PLN m谩s complejas, pero transformers nos da acceso a modelos entrenados para tareas como la b煤squeda de respuestas que tienen un rendimiento sorprendentemente bueno, al menos en ingl茅s. Vamos a comprobar qu茅 tal funcionan.\n",
    "\n",
    "Lo primero es cargar el extractor de respuestas con el modelo por defecto en ingl茅s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = pipeline(\"question-answering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaci贸n definimos una serie de pares pregunta-contexto, con textos en lenguaje natural pegados directamente de art铆culos de Wikipedia.\n",
    "\n",
    "El modelo de b煤squeda de respuestas es de tipo extractivo, no generativo. Esto implica que el modelo espera procesar e interpretar una pregunta y un contexto, susceptible de contener la respuesta. Intentar谩 interpretar el tipo de pregunta y devolver谩 el segmento del contexto con mayor probabilidad de ser la respuesta. Ten en cuenta que el modelo es extractivo, por lo tanto es incapaz de reescribir la respuesta.\n",
    "\n",
    "Con estos ejemplos funciona perfectamente. Parece que hemos alcanzado la singularidad y que la humanidad est谩 a merced de las m谩quinas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What city are the Lakers from?\n",
      "{'score': 0.2602875530719757, 'start': 4, 'end': 15, 'answer': 'Los Angeles'} \n",
      "\n",
      "LeBron James date of birth\n",
      "{'score': 0.9441075921058655, 'start': 50, 'end': 68, 'answer': 'December 30, 1984)'} \n",
      "\n",
      "Who won the NBA finals?\n",
      "{'score': 0.2531222105026245, 'start': 221, 'end': 239, 'answer': 'Los Angeles Lakers'} \n",
      "\n",
      "What was the score?\n",
      "{'score': 0.955236554145813, 'start': 293, 'end': 297, 'answer': '42,'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "preguntas_contextos = [\n",
    "    {\n",
    "        \"question\": \"What city are the Lakers from?\",\n",
    "        \"context\": \"The Los Angeles Lakers are an American professional basketball team based in Los Angeles.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"LeBron James date of birth\",\n",
    "        \"context\": \"LeBron Raymone James Sr. (/lbrn/ l-BRON; born December 30, 1984) is an American professional basketball player for the Los Angeles Lakers of the National Basketball Association (NBA).\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Who won the NBA finals?\",\n",
    "        \"context\": \"The 2020 NBA Finals was the championship series of the National Basketball Association (NBA)'s 201920 season and conclusion of the season's playoffs. In this best-of-seven playoff series, the Western Conference champion Los Angeles Lakers defeated the Eastern Conference champion Miami Heat, 42, winning their first NBA championship in ten years.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What was the score?\",\n",
    "        \"context\": \"The 2020 NBA Finals was the championship series of the National Basketball Association (NBA)'s 201920 season and conclusion of the season's playoffs. In this best-of-seven playoff series, the Western Conference champion Los Angeles Lakers defeated the Eastern Conference champion Miami Heat, 42, winning their first NBA championship in ten years.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for ejemplo in preguntas_contextos:\n",
    "    print(ejemplo[\"question\"])\n",
    "    print(qa(ejemplo), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, cuando el modelo recibe un contexto no directamente relacionado con la pregunta, empieza a dudar y le vemos las verg眉enzas. Claramente no entiende lo que est谩 haciendo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.3653542399406433, 'start': 67, 'end': 75, 'answer': 'American'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\n",
    "    {\n",
    "        \"question\": \"What are you from?\",\n",
    "        \"context\": \"The New York Times (NYT), sometimes also known as The Times, is an American newspaper based in New York City with worldwide influence and readership\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.12368953973054886, 'start': 0, 'end': 4, 'answer': 'Love'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\n",
    "    {\n",
    "        \"question\": \"What's the capital city of Spain?\",\n",
    "        \"context\": \"Love is in the air, in the whisper of the trees. Love is in the air, in the thunder of the sea.\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumen autom谩tico con transformers\n",
    "\n",
    "Otra de las tareas que combinan NLU y NLP que tenemos disponible en transformers con muy pocas l铆neas de c贸digo es el resumen autom谩tico. Si creamos un *pipeline* para resumir, podremos procesar documentos largos de entrada y seleccionar aquellas frases que mejor resuman el contenido sem谩ntico del documento original.\n",
    "\n",
    "Ten en cuenta que, en muchas ocasiones, a estos res煤menes les faltar谩 la naturalidad, la coherencia y la cohesi贸n t铆pica de un resumen hecho a mano por seres humanos, pero el resultado s铆 que sintetizar谩 el contenido de manera satisfactoria, lo que puede ser suficiente en muchos contextos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargado el modelo, veamos qu茅 tal funciona con textos extra铆dos de Wikipedia y de la prensa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' The New York Times (NYT) is an American newspaper based in New York City . Founded in 1851, the paper has won 130 Pulitzer Prizes, more than any other newspaper . It is ranked 18th in the world by circulation and 3rd in the U.S.'}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documento_largo = \"\"\"The New York Times (NYT), sometimes also known as The Times,[6] is an American newspaper based in New York City with worldwide influence and readership.[7][8] Nicknamed \"the Gray Lady\",[9] the Times has long been regarded within the industry as a national \"newspaper of record\".[10] The paper's motto, \"All the News That's Fit to Print\", appears in the upper left-hand corner of the front page. Founded in 1851, the paper has won 130 Pulitzer Prizes, more than any other newspaper.[11][12] It is ranked 18th in the world by circulation and 3rd in the U.S.[13]\n",
    "\n",
    "The paper is owned by The New York Times Company, which is publicly traded. It has been owned by the Sulzberger family since 1896 through a dual-class share structure.[14] A. G. Sulzberger and his father, Arthur Ochs Sulzberger Jr.the paper's publisher and the company's chairman, respectivelyare the fourth and fifth generation of the family to head the paper.[15]\n",
    "\n",
    "Since the mid-1970s, The New York Times has greatly expanded its layout and organization, adding special weekly sections on various topics supplementing the regular news, editorials, sports, and features. Since 2008,[16] the Times has been organized into the following sections: News, Editorials/Opinions-Columns/Op-Ed, New York (metropolitan), Business, Sports, Arts, Science, Styles, Home, Travel, and other features.[17] On Sundays, the Times is supplemented by the Sunday Review (formerly the Week in Review),[18] The New York Times Book Review,[19] The New York Times Magazine,[20] and T: The New York Times Style Magazine.[21]\n",
    "\n",
    "The Times stayed with the broadsheet full-page set-up and an eight-column format for several years after most papers switched to six,[22] and was one of the last newspapers to adopt color photography, especially on the front page.[23]\n",
    "\"\"\"\n",
    "\n",
    "summarizer(documento_largo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Rafael Nadal equalled Roger Federer's record of 20 Grand Slam men's singles titles . Nadal defeated Novak Djokovic 6-0 6-2 7-5 to claim his 13th French Open title . Federer thanked Nadal and said their relationship \"means a lot\" Nadal: \"I have always had the utmost respect for my friend Rafa\"\n"
     ]
    }
   ],
   "source": [
    "documento_largo_2 = \"\"\"Roger Federer hailed his \"greatest rival\" after Rafael Nadal equalled his record of 20 Grand Slam men's singles titles in devastating fashion.\n",
    "\n",
    "Nadal, 34, comprehensively outplayed the other member of the sport's 'Big Three', Novak Djokovic 6-0 6-2 7-5 to claim his 13th French Open title.\n",
    "\n",
    "\"I have always had the utmost respect for my friend Rafa as a person and as a champion,\" the Swiss great tweeted.\n",
    "\n",
    "In response, Nadal thanked Federer and said their relationship \"means a lot\".\n",
    "\n",
    "The Spaniard continued: \"As everybody know we have a very, very good relationship and we respect each other a lot and at the same time I think he is happy when I am winning and I'm happy when he is doing things well.\n",
    "\n",
    "\"In some ways it means a lot, the positive relationship we have together because we have been going through a great rivalry for a very, very long time.\"\n",
    "\n",
    "Federer, who missed Roland Garros this year after knee surgery, added: \"I hope 20 is just another step on the continuing journey for both of us.\n",
    "\n",
    "\"As my greatest rival over many years, I believe we have pushed each other to become better players.\n",
    "\n",
    "\"Therefore, it is a true honour for me to congratulate him on his 20th Grand Slam victory. It is especially amazing that he has now won Roland Garros an incredible 13 times, which is one of the greatest achievements in sport.\n",
    "\"\"\"\n",
    "\n",
    "print(summarizer(documento_largo_2)[0][\"summary_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "En esta segunda nota t茅cnica, hemos presentado tres de las librer铆as de Python m谩s populares para realizar tareas de procesamiento del lenguaje natural: [spaCy](http://www.spacy.io/), [flair](https://github.com/flairNLP/flair) y [transformers](https://huggingface.co/transformers/).\n",
    "\n",
    "Hemos aprendido c贸mo cargar modelos pre-entrenados que est谩n disponibles en todas ellas para realizar tareas b谩sicas de NLU como son la tokenizaci贸n, el an谩lisis morfo-sint谩ctico y el reconocimiento de entidades y tareas no tan b谩sicas como la b煤squeda de respuestas y el resumen autom谩tico."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
